{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the SURF-NEMO User Guide","text":"<p>version 1.1, This user guide provide documentation for the Structured and Unstructured grid Relocatable ocean platform for Forecasting (SURF) (release version 1.01).</p> <p>Please read the release notes to see what has changed since the previous release.</p>      Note: The documentation is also available in PDF format:     surf_nemo_1.01.pdf. <p>You can download the new SURF-NEMO release from the page https://www.surf-platform.org</p>      Copyright:      SURF is a free and open source software packages distributed under the terms of the GNU General Public     License (GPLv3)."},{"location":"appA_reference-configuration/","title":"Reference Configuration","text":""},{"location":"appA_reference-configuration/#reference-configuration-for-nemo","title":"Reference Configuration for NEMO","text":"<p>Part of the input model parameters are fixed and defined inside the SURF source package in the file 'setParFix:ncl'..... The Monotonic Upstream Scheme for Conservation Laws (MUSCL) was used for the tracer advection and the Energy and Enstrophy conservative (EEN) scheme was used for the momentum advection (Arakawa and Lamb 1981; Barnier et al. 2006). No-slip conditions on closed lateral boundaries were applied and the bottom friction was param- eterised by a quadratic function.</p>"},{"location":"appB_scratch-partition-and-its-directory-structures/","title":"Scratch Partition and its directory structures","text":"<p> As shown in  chapter 6.1.1 the VM surf is divided into two partitions: the disk <code>/dev/sda</code> \"mounted\" in the root directory <code>/</code> and the disk <code>/dev/sdb</code> \"mounted\" in the directory <code>/scratch</code>. The scratch partition contains all the SURF packages and follows the directory structure as shown in figure B.1: The up-to-date version release is structured as follow:</p> <ul> <li>         The directory <code>surf_install/</code> contains the utilities necessary to manage all the operations of creation         and installation of each package of the SURF platform.     </li> <li>         The directory <code>surf_datasets/</code> contains a list of static input datasets needed to run the SURF_NEMO         package. With 'static' we mean here datasets which do not depend on the selected simulation         period; i.e. bathymetry, coastline, parent meshmask, weight for remapping, meshmask and bathymetry         remapped on the child grid.     </li> <li>         The directory <code>surf_nemo/</code> contains the sources code of the SURF-NEMO package.     </li> <li>         The directory <code>experiments/</code> contains all the experiments you have executed.     </li> </ul> <p>We describe here the contents of these directories.</p> Fig. B.1 SURF package directories tree."},{"location":"appB_scratch-partition-and-its-directory-structures/#the-surf_install-directory-structure","title":"The surf_install directory structure","text":"<p>The SURF-INSTALL package is pre-installed in the SURF platform and it is located in the directory <code>/scratch/surf/surf_install</code>. The folder <code>surf_install_1.00</code> has the directory structure as in figure B.1:</p> <ul> <li>The folder <code>scripts/</code> containing the bash scripts to install (<code>install.sh</code>)     and to create (<code>dorelease.sh</code>) packages release.</li> <li>The text file <code>ChangeLog.txt</code> containing documentation of all notable changes to the 'surf_install' package.</li> <li>The text file <code>ReadMe.txt</code> describing of the contents of the 'surf_install' package.</li> <li>The bash file <code>vertion.sh</code> containing the version number of the 'surf_install' package.     This number is displayed in the upper-right corner of VM desktop</li> </ul>"},{"location":"appB_scratch-partition-and-its-directory-structures/#the-surf_nemo-directory-structure","title":"The surf_nemo directory structure","text":"<p>Once installed (see  section 6.2), the SURF-NEMO package is located in the directory <code>/scratch/surf/surf_nemo/</code>. The folder <code>surf_nemo_1.00</code> has the directory structure as in figure B.1:</p> <ul> <li>     The folder <code>nemo/</code> contains the source code of the NEMO ocean model (v3.6).     </li> <li>     The folder <code>scripts/</code> contains the scripts for the pre- and post-processing needed to execute the relocatable SURF model.     </li> <li>     The folder <code>utilities/</code> contains the source code of several utility functions used for specific tasks in the pre-/post-processing.     </li> <li>     The json file <code>setParFree.json</code> of the template configuration file for the case study experiment.     </li> <li>     The text file <code>ChangeLog.txt</code> containing the documentation of all notable changes to the 'surf_nemo' package.     </li> <li>     The text file <code>ReadMe.txt</code> describing of the contents of the 'surf_nemo' package.     </li> <li>     The text file <code>Licence.txt</code> containing the product licensing information.     </li> <li>     The bash file <code>vertion.sh</code> containing the version number of the 'surf_nemo' package. This number is displayed in the upper-right corner of VM desktop.     </li> </ul>"},{"location":"appB_scratch-partition-and-its-directory-structures/#the-surf_datasets-directory-structure","title":"The surf_datasets directory structure","text":"<p>Once installed (see section xx), the SURF-DATASETS package is located in the directory <code>/scratch/surf/surf_datasets</code>. The folder <code>surf_datasets_1.00</code> has the directory structure as in figure B.1:</p> <ul> <li>     The folder <code>bathymetry/</code> contains the GEBCO Bathymetric datasets at 30 arc seconds resolution.     </li> <li>     The folder <code>coastline/</code> contains the GSHHG coastline datasets provided by the NOAA National Geophysical Data Center (NGDC).     </li> <li>     The folder <code>meshmask/</code> contains the meshmask files of the parent ocean model and atmosphere source.     </li> <li>     The folder <code>experiments_regrid/</code> used when you want execute the SURF platform operationally.     It contains the weight files for remapping ocean and atmospheric input data, the meshmask and     bathymetry remapped on the child grid.     </li> <li>     The text file <code>ChangeLog.txt</code> containing the documentation of all notable changes to the 'surf_datasets' package.     </li> <li>     The text file <code>ReadMe.txt</code> describing of the contents of the 'surf_datasets' package.     </li> <li>     The bash file <code>vertion.sh</code> containing the version number of the 'surf_datasets' package.     This number is displayed in the upper-right corner of VM desktop.     </li> </ul>"},{"location":"appB_scratch-partition-and-its-directory-structures/#the-experiments-directory","title":"The experiments directory","text":"<p> Once the experiment is executed (i.e. expID), it is located in the directory <code>/scratch/surf/experiments/</code>. The folder <code>expID</code> has the directory structure as in figure B.1:</p> <ul> <li>     A copy of the configuration file <code>setParFree.json</code> (copied from the directory surf/from_GUI/expID/).     </li> <li>     The folder <code>code/</code> contains a copy of the source code (from the directory surf/surf_nemo/current/)     used to execute the simulation.     </li> <li>     The folder <code>data/</code> contains all the data used in the experiment:     the original input data (<code>data/indata/</code>),     the extrapolated data (<code>data/extrapoldata/</code>), the regridded data (<code>data/regriddata/</code>)     and the output data (<code>./data/outdata/</code>)     The input datasets are downloaded from a local or web repositories for the selected period of simulation.     </li> <li>     The folder <code>figure/</code> contains all the plots of the original input data (<code>figure/indata/</code>),     extrapolated data (<code>figure/extrapoldata/</code>), regridded data (<code>figure/regriddata/</code>),     output data (<code>./figure/outdata/</code>), comparison between child and the parent coarse resolution data,...     </li> </ul>"},{"location":"appC_linux-root-partition-and-the-installed-packages/","title":"Linux Root Partition and the installed packages","text":"<p> As shown in  chapter 6.1.1 the VM surf is divided into two partitions: the disk <code>/dev/sda</code> \"mounted\" in the root directory <code>/</code> and the disk <code>/dev/sdb</code> \"mounted\" in the directory <code>/scratch</code>. The root partition contains Debian GNU/Linux operating system (version 10.7).</p>"},{"location":"appC_linux-root-partition-and-the-installed-packages/#debian-partition","title":"Debian partition","text":"<p> The operating system installed in the Virtual Machine is Debian. Debian is a free operating system (OS) that use the Linux kernel. It comes with over 59000 packages, precompiled software bundled up in a nice format for easy installation on your machine.</p> <p> In the current VM is installed Debian 10 buster. You can find the list of packages here.</p>"},{"location":"appC_linux-root-partition-and-the-installed-packages/#installed-packages","title":"Installed packages","text":""},{"location":"appC_linux-root-partition-and-the-installed-packages/#cdo-v181","title":"CDO - (v1.8.1)","text":"<p> The Climate Data Operator (CDO) software is a collection of many operators for standard processing of climate and forecast model data. The operators include simple statistical and arithmetic functions, data selection and subsampling tools, and spatial interpolation. CDO was developed to have the same set of processing functions for GRIB [GRIB] and NetCDF [NetCDF] datasets in one package.</p>"},{"location":"appC_linux-root-partition-and-the-installed-packages/#curl-v7521","title":"curl - (v7.52.1)","text":"<p> curl is free and open source software used in command lines or scripts to transfer files/data from or to a server using FTP, HTTP, HTTPS, SCP, SFTP, SMB and other supported protocols on Linux or Unix-like system. </p>"},{"location":"appC_linux-root-partition-and-the-installed-packages/#hdf5-v1818","title":"HDF5 - (v1.8.18)","text":"<p> The Hierarchical Data Format (HDF5) is a data model, library, and file format for storing and managing data. It supports an unlimited variety of datatypes, and is designed for flexible and efficient I/O and for high volume and complex data. HDF5 is portable and is extensible, allowing applications to evolve in their use of HDF5. The HDF5 Technology suite includes tools and applications for managing, manipulating, viewing, and analyzing data in the HDF5 format. </p>"},{"location":"appC_linux-root-partition-and-the-installed-packages/#julia-v141","title":"Julia - (v1.4.1)","text":"<p> Julia is a high-level, high-performance, dynamic programming language. While it is a general purpose language and can be used to write any application, many of its features are well-suited for high-performance numerical analysis and computational science. </p>"},{"location":"appC_linux-root-partition-and-the-installed-packages/#mpich2-v32","title":"MPICH2 - (v3.2)","text":"<p> MPICH, formerly known as MPICH2, is a freely available, high performance and widely portable implementation of the Message Passing Interface (MPI) standard.     It efficiently supports different computation and communication platforms including commodity clusters, SMPs, massively parallel systems, and high-speed networks.</p>"},{"location":"appC_linux-root-partition-and-the-installed-packages/#ncl-v640","title":"NCL - (v6.4.0)","text":"<p> The NCAR Command Language (NCL) is a free interpreted language designed specifically for scientific data processing and visualization. </p>"},{"location":"appC_linux-root-partition-and-the-installed-packages/#ncview-v217","title":"Ncview - (v2.1.7)","text":"<p> Ncview is a visual browser for netCDF format files. Typically you would use ncview to get a quick and easy, push-button look at your netCDF files. You can view simple movies of the data, view along various dimensions, take a look at the actual data values, change color maps, invert the data, etc.  </p>"},{"location":"appC_linux-root-partition-and-the-installed-packages/#netcdf-4411","title":"NetCDF - (4.4.1.1)","text":"<p> Network Common Data Form (NetCDF) is a set of software libraries and machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data. It is also a community standard for sharing scientific data. </p>"},{"location":"appC_linux-root-partition-and-the-installed-packages/#python-369","title":"Python - (3.6.9)","text":"<p> Python is an interpreted, high-level, general-purpose programming language. </p>"},{"location":"appC_linux-root-partition-and-the-installed-packages/#szip-v21","title":"Szip - (v2.1)","text":"<p> Szip compression software, providing lossless compression of scientific data.  </p>"},{"location":"appC_linux-root-partition-and-the-installed-packages/#udunits-v2224","title":"UDUNITS - (v2.2.24)","text":"<p> The UDUNITS package supports units of physical quantities. Its C library provides for arithmetic manipulation of units and for conversion of numeric values between compatible units. The package contains an extensive unit database, which is in XML format and user-extendable. The package also contains a command-line utility for investigating units and converting values.</p>"},{"location":"appC_linux-root-partition-and-the-installed-packages/#xios","title":"XIOS","text":"<p> XIOS is library designed to manage NETCDF outputs of climate models.</p>"},{"location":"appC_linux-root-partition-and-the-installed-packages/#zlib-v1211","title":"zlib - (v1.2.11)","text":"<p> The zlib compression library provides in-memory compression and decompression functions, including integrity checks of the uncompressed data. </p>"},{"location":"appD_release-notes/","title":"Release Notes","text":"<p>surf_nemo - Version 1.01 \"What's New\" (released on 2020-11-08) All notable changes to this package will be documented here.</p>"},{"location":"appD_release-notes/#added","title":"Added","text":"<ul> <li>Regridding of the barotropic tide fields (elevation, zonal and merdional velocity) (in 'run_regriddataTideBC.jl')</li> <li>Extraction of the tide on the lateral open boundary (in 'run_regriddataTideBC.jl')</li> <li>Rotation of the ocean velocity components when parent model is defined on a distorted curvilinear spherical grid (add rotateUV and interpUV packages in the utilities directory)</li> <li>Several parameters in the configuration file setParFree.json</li> </ul>"},{"location":"appD_release-notes/#changed","title":"Changed","text":"<ul> <li>Split the main.ncl procedure in 5 indipendent macrotask: run_childMeshMask.ncl,   regriddataAtm.ncl,run_regriddataOceIC.ncl run_regriddataTideBC.jl,run_oce.ncl</li> <li>Rewritten several procedure from ncl to julia programming language</li> </ul>"},{"location":"appE_bibliography/","title":"Bibliography","text":"<ol> <li> <p>Engerdahl H (1995),         Use of the flow relaxation scheme in a threedimensional baroclinic ocean model with realistic topography.,         Tellus 47A:365\u2013382</p> </li> <li> <p>Oddo P, Pinardi N (2008),         Lateral open boundary conditions for nested limited area models: A scale selective approach.,         Ocean Model 20:134\u2013156</p> </li> <li> <p>Richtmyer R (1957),         Difference methods for initial-value problems.,         Published by Interscience Publishers</p> </li> <li> <p>Shapiro R (1970),         Smoothing, filtering, and boundary effects.,         Rev Geophys Space Phys 8:359\u2013387</p> </li> <li> <p>Shapiro R (1975),         Linear filtering.,         Math Comput 29:1094\u20131097</p> </li> <li> <p>N. Pinardi et al. (2003),         The Mediterranean ocean forecasting system: first phase of implementation (1998\u20132001).,         Annales Geophysicae, 21: 3-20</p> </li> </ol>"},{"location":"ch1_introduction/","title":"Introduction","text":"<p>The Structured and Unstructured grid Relocatable ocean platform for Forecasting (SURF) is an open-source package designed to generate high-resolution, nested model set-ups for oceanic forecasts over limited domains of interest. It is designed to be set up by relatively non-expert users in any region of the World Ocean using a configuration file. The package will enable limited area ocean forecasts to be run on any commercially available personal computer or laptop.     SURF requires coarser-resolution ocean forecasts for the initial and boundary conditions and atmospheric forcing to force the circulation. </p> <p>This User Guide describes the overall design of the structured grid component of the SURF platform based on the     NEMO ocean model (SURF-NEMO).     In addition to step-by-step information about running the platform, the User Guide gives a detailed description of the scripts organization and the data structures, so that SURF can be modified/integrated by users.     This User Guide gives also provides a case study using available input datasets for bathymetry, the coastline, atmospheric forcing, and the coarser-resolution parent ocean model along with output datasets to check the correct implementation of the software.</p> <p>Information about the SURF numerical platform is also provided on the home page</p> <p>https://www.surf-platform.org</p> <p>SURF also contains the unstructured grid model SHYFEM, which will be explained in a future update of the User Guide.</p>"},{"location":"ch1_introduction/#relocatable-ocean-modelling-system","title":"Relocatable ocean modelling system","text":"SURF-NEMO (Trotta et al.      2016,     2021)     provides a numerical platform for forecasting hydrodynamic and thermodynamic     fields at high spatial and temporal resolutions. SURF-NEMO is designed to be embedded in any region of a larger-scale     ocean prediction system, at coarser-resolution, and includes multiple nesting capabilities (i.e., consecutive nested     models can be implemented with increasing grid resolutions), starting with the first nesting in a large-scale ocean     model and reaching horizontal grid resolutions of a few hundred metres. For each nesting, the parent coarse-grid model     provides the initial and lateral boundary conditions for the SURF child components. <p>This relocatable ocean model system is intended to be a valuable tool that supports other Decision Support System     (DSS) that may require hydrodynamic, temperature and salinity forecasts at high resolution, such as oil spill monitoring,     search and rescue operations, navigation routing, fisheries and tourism.</p>"},{"location":"ch1_introduction/#virtual-machine-environment","title":"Virtual Machine Environment","text":"<p>SURF-NEMO is based on a virtual machine environment in which the hydrodynamic NEMO model and several pre-     and post-processing tools are connected to the required input fields and the numerical outputs of the limited area simulation.     The Installation Chapter (6.1) provides details of     how to download and install the package.</p> <p>A virtual machine is a software-based computer that enables the emulation of operating systems with     \"virtual\" access to hardware resources such as CPU, RAM, networking and storage. The operating     system that runs inside a virtual machine is called the guest, which appears in a window on your computer's     own operating system, commonly referred to as the host.</p> <p>The virtualization software used is the free and open-source Oracle VM VirtualBox package, on which     the Debian Linux operating system was installed.</p> <p>Virtual machines offer many advantages and can encapsulate an entire PC environment including the operating     system, applications and all data, inside a single file. As a packaged application, it is easier to set up     than installing a full suite of software that must work together. The virtual machine can be distributed     as a ready-made and fully configured system, anf thus has advantages for configuration and distribution.     A virtual machine can also run on various hardware platforms.</p>"},{"location":"ch1_introduction/#source-code","title":"Source Code","text":"<p>The SURF source codes are contained in a package distributed as a tar.gz archive. The archive     contains the NEMO code, the pre- and post-processing codes and a template user-configuration file.     The Installation Chapter (6.2) describes how to download     and install the package.</p> <p>NEMO consists of open-source code written in Fortran 90 and is parallelized with a domain decomposition using     the MPI library. The model outputs from the SURF-NEMO simulations are all in NetCDF format.</p> <p>The pre- and post-processing code are developed in Julia, NCL, Python and Fortran programming languages.     The NetCDF Operator (NCO) and Climate Data Operators (CDO) are used to facilitate the manipulation of the NetCDF datasets.     These tools are specifically developed and optimised for SURF to reduce the computation latency and to ensure     efficient memory usage. Currently, pre- and post-processing can only be run in serial mode     (i.e., only executed on one processor). The structure of the SURF source code package is shown in     appendix B.</p>"},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/","title":"Workflow of the SURF-NEMO platform","text":"<p>The schematic work-flow diagrams in Fig. 2.1 shown the step involved in the SURF-NEMO numerical platform.     The steps in the most recent version release are grouped as follows:</p> <ol> <li> <p>Initialization: the user specifies the values of the input simulation parameters for the ocean model in the configuration file (horizontal and vertical grids, subgrid scale parameterizations, etc.) for the specific experiment selected.</p> </li> <li> <p>Access and download of the input datasets: this is an automated step in which the input datasets for the selected simulation period are downloaded from remote or local data repositories, as specified in the configuration file. The input data are the bathymetry, the coastline, the atmospheric forcing and the coarse resolution parent ocean model for the initial and lateral boundary condition datasets.</p> </li> <li> <p>Spatial numerical grid generation: this is an automated step that generates the horizontal and vertical grid for the nested model.</p> </li> <li> <p>Input data regridding: this is an automated step that generates the bottom topography, surface forcing, initial and open lateral boundary conditions datasets on the child grid.</p> </li> <li> <p>Forecast: another automated step in which the NEMO code is exectuted to produce the final outputs.</p> </li> <li> <p>Post-processing: in this step the visualization and analysis procedures of the final outputs are considered. Different options of postoprocessing are available, i.e. comparing parent/child fields, comparing the simulation results with in-situ or satellite datasets and converting the datasets into what?</p> </li> </ol> Work-flow of the Relocatable SURF-NEMO platform. <p>The graphical calling function flow shown in Figure 2.2 represent    all paths traversed through a program during its execution and shows how the program is completed from start to finish,    step-by-step. The six macro-tasks identified are: (1) child meshmask generation; (2) atmospheric data regridding;    (3) ocean IC data regridding; (4) ocean BC data regridding and OBC data extraction; (5) ocean model simulation;    and (6) visualization and data analysis.</p> Graphical calling function flow of the Relocatable SURF-NEMO platform. <p>The computational tasks are not independent of each other. The dependency flow graph of the macrotasks is given    in Figure 2.3.    Each node (from A to F) represents a macro-task and the solid edges represent data dependencies among these macro-tasks.    From node A, tree edge can take us to node B, node C and D. Node E can begin once all the lower nodes are completed.</p> Dependency flow graph of macro-tasks."},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#setting-up-the-input-model-parameters","title":"Setting up the input model parameters","text":"<p>The first task executed by each macro-task consists of setting up the values of the input model parameters,       which are obtained from the configuration files <code>setParFree.json</code> and <code>setParFixed.json</code>.       The configuration file structure and the input parameters are described in       Chapter 3 and       Appendix A.       In this phase, the <code>read_inJsonFree</code> and <code>read_inJsonFixed</code> procedures are executed       to respectively define the user-free and fixed input parameters required to execute the NEMO model and all of       the pre- and post-processing tasks.       The procedures <code>set_pathData</code> and <code>set_fileData</code> are also called to define all of the paths       and file names used by the program for the specific numerical simulation.     </p>"},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#child-meshmask-generation","title":"Child Meshmask Generation","text":"<p>The child grid is generated after the model configuration phase. The NEMO model uses the Arakawa C grid for       spatial discretization, with the state variables defined on the staggered grid illustrated       in Figure 2.4. In the C grid the scalar quantities (temperature T, salinity S, pressure p,       density \\(\\rho\\)) are defined at the center of each grid volume. The velocity field components (zonal u, meridional       v and vertical w) are shifted by half a grid width in their respective direction so that they are defined at       the edges of the grid volumes. The procedures executed in this phase are:</p> <ul> <li><p>Generation of the child 2D-mesh.</p></li> <li><p>Interpolation of the source bathymetric dataset on the generated child grid.</p></li> <li><p>Generation of the child 3D-meshmask.</p></li> </ul> The staggered Arakawa C-grid used by NEMO ocean model."},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#horizontal-grid","title":"Horizontal grid","text":"<p>The horizontal grid generation is managed by the NEMO-MESH code. SURF uses ONLY a rectangular     (or latitude-longitude) grid in a spherical coordinate system \\(\\lambda,\\varphi\\).     The horizontal grid (expressed in degrees) is generated by specifying the number of points     \\(n_{\\lambda}\\) and \\(n_{\\varphi}\\),respectively, in zonal and     meridional directions, and the respective grid sizes \\(\\Delta\\lambda\\) and     \\(\\Delta\\varphi\\) (in degrees) and the longitude and latitude \\((\\lambda,\\varphi)_{1,1}\\)     of the first row and first column of the T grid. On the \\(\\lambda\\varphi\\) plane,     the location of the T points of the grid are:</p> $$     \\begin{equation}     \\begin{array}{ll}         \\lambda_{i,j} = \\lambda_{11} + (i-1) \\Delta \\lambda   \\hspace{0.5cm} \\mbox{with} \\hspace{0.2cm} i=1.....n_\\lambda         \\\\         \\varphi_{i,j} = \\varphi_{11} + (j-1) \\Delta \\varphi   \\hspace{0.5cm} \\mbox{with} \\hspace{0.2cm} j=1.....n_\\varphi     \\end{array}     \\end{equation}     $$ <p>The u, v points of the grid are shifted by half a grid width in the zonal e/o meridional direction, as indicated     in Fig. 2.4.</p>"},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#bathymetry-regridding","title":"Bathymetry regridding","text":"In this phase the bathymetric dataset is interpolated on the child grid, which is required to generate the 3D meshmask.     The procedures in this phase are: <ul> <li><p>Accessing and downloading the source bathymetry and the coastline datasets.</p></li> <li><p>Manipulating the bathymetry dataset.</p></li> <li><p>The spatial interpolation of the source bathymetric on the child grid.</p></li> </ul>"},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#access-the-bathymetry-and-coastline-datasets","title":"Access the bathymetry and coastline datasets","text":"<p>A procedure for checking if the necessary input datasets are present in the experiment directory     <code>$PATH_IDEXP/data/data00/indata/</code> is executed.     If some of the requested data are not present then the procedures <code>downlCoastlineInfile</code> and     <code>downlBathyInfile</code> are automatically executed to download the coastline and the bathymetry,     respectively, from remote or local data repositories as specified in the configuration file     <code>setParFree.json</code>.</p>"},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#manipulating-and-smoothing-bathymetry","title":"Manipulating and smoothing bathymetry","text":"<p>Before conducting the spatial interpolation on the child grid, the source bathymetry data product can be manipulated if specified in the configuration file setParFree.json. Several methods can be used:</p> <ul> <li> <p>Add a constant value to the surface elevation for the whole nested region         (e.g., an inland body of water with water level below the global ocean level such as the Caspian Sea).</p> </li> <li> <p>Set maximum and minimum values that are different from the source value         (e.g., if a minimum depth of 5 metres or a maximum depth of less than the actual depth is required).</p> </li> <li> <p>Define the land/sea interface grid points according to the input coastline.</p> </li> <li> <p>Set maximums and minimums inside sub-regions (e.g., to mask a specific area)</p> </li> <li> <p>Smooth out bathymetry variations with the Shapiro filter.         This is a high order horizontal filter that efficiently removes small scale grid noise without affecting         the physical structures of a field. A Shapiro filter of a 2N order of accuracy is applied to a variable         based on the expression:</p> $$     \\begin{equation}         \\label{eq:shapiro_filter}         \\tilde{w_i} = F^{2N}(w_i) =  \\left[  I + (-1)^{N-1}  \\frac{\\delta^{2N}}{2^{2N}}  \\right] (w_i) = w_i + (-1)^{N-1}  \\frac{\\delta^{2N} w_i}{2^{2N}}     \\end{equation}     $$ <p> where \\(\\tilde{w_i}\\) is the filtered value of variable \\(w\\)     at point \\(x_i\\), \\(I\\) is the identity operator and \\(\\delta^{2N}\\)     is the even composition of the standard difference operator \\(\\delta\\)     (Richtmyer, 1957).     This filter is a discrete symmetric operator with a (2N + 1) point stencil.     It acts as a low-pass filter that preserves the low-frequency content (i.e., largest wavelengths)     and completely dissipates the high-frequency content (i.e., shortest wavelengths) from the original field.</p></li> </ul>"},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#interpolation-of-bathymetric-data","title":"Interpolation of bathymetric data","text":"<p> The spatial interpolation of the source bathymetric dataset on the child grid can be conducted after the manipulation of the source bathymetry phase. The procedures are based on the Spherical Coordinate Remapping and Interpolation Package (SCRIP) code. The interpolation methods available are listed and described in Section 3.</p>"},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#meshmask-and-vertical-grid","title":"Meshmask and Vertical grid","text":"<p>The vertical grid generation is managed by the NEMO-MESH code. The type of vertical grid used in SURF corresponds to geopotential z-coordinate levels with partial bottom cell representation of the bathymetry. After the bathymetry \\(z = H(\\lambda,\\varphi)\\) and the number of levels \\(n_{z}\\) have been specified, the vertical location of w- and t-levels (expressed in metres) are defined, except in the bottom layer, from the following analytic expression:</p> $$ \\begin{equation}     z(k) = h_{sur} - h_{0} k - h_{1} log [cosh (( k - h_{th}) h_{cr})] \\end{equation} $$ <p>where the coefficients \\(h_{sur}\\), \\(h_0\\), \\(h_1\\), \\(h_{th}\\) and \\(h_{cr}\\) are the parameters to be specified. \\(h_{cr}\\) represents the stretching factor of the grid and \\(h_{th}\\) is the approximate model level at which maximum stretching occurs. This expression enables stretched z-coordinate vertical levels to be defined, which are smoothly distributed along the water column, with appropriate thinning designed to better resolve the surface and intermediate layers. Through partial cell parameterization, the thickness of the bottom layer can vary as a function of the geographical location \\((x,y)_{i,j}\\) which allows a better representation of the real bathymetry.</p> (A) Horizontal grid. (B) Vertical T-grid. Example of horizontal (left) and vertical (right) numerical grid with, respectively, grid sizes of \\(\\Delta\\lambda\\)\u0001\u0015 and \u0001\\(\\Delta\\varphi\\) in horizontal and \\(\\Delta z\\) in vertical direction."},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#input-data-regridding","title":"Input data Regridding","text":"<p>Regridding, also called remapping, is the process of changing the grid (from a source to a destination grid) underlying the field data values while preserving the qualities of the original data. In this section we describe the spatial extrapolation and interpolation procedure used in in SURF to remap the input fields on the child grid. This phase will generate the surface forcing, initial and open lateral boundary condition datasets on the child grid. The procedures in this phase are:</p> <ul> <li><p>Accessing and downloading the input datasets</p></li> <li><p>Rotation of the vector fields (if required)</p></li> <li><p>Extrapolation of the input datasets</p></li> <li><p>Spatial interpolation of the source dataset on the child grid</p></li> <li><p>Lateral Open Boundary Condition dataset generation</p></li> </ul>"},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#access-and-download-of-the-input-datasets","title":"Access and download of the input datasets","text":"<p>A procedure for checking if the necessary input datasets are in the experiment directory <code>$PATH_IDEXP/data/</code> is executed. If any of the requested data are not present then the procedures <code>downlAtmSrc</code>, <code>downlOceICSrc</code> and <code>downlOceBCSrc</code> are automatically executed to respectively download the atmospheric forcing and the initial and lateral boundary condition datasets for the selected period of the simulation from remote or local data repositories, as specified in the configuration file <code>setParFree.json</code>.</p>"},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#rotation-of-horizontal-velocity-u-v","title":"Rotation of horizontal velocity u, v","text":"<p>When the parent coarse resolution model is defined on a rotated or a curvilinear grid (e.g., the global tripolar grid, Fig. 2.6(a)) one more step is required to interpolate the horizontal velocity fields on the child grid. In an ocean model with a \u201cdistorted\u201d grid, the velocity vectors are obtained according to the direction of the grid lines. In a staggered Arakawa C grid system, the velocity field components are defined at the cell edges (the gray arrows in Fig. 2.6(b)). A rotation in the latitudinal and longitudinal directions of the velocity components must be applied to change the vectors from the local system \\((x,y)\\) to a geographical system \\((x^{'},y^{'})\\), so that U gives the zonal component (W-E direction) and V the meridional component (S-N direction) of the velocity vector. Therefore, to transform the \\((x,y)\\) coordinates to the \\((x^{'},y^{'})\\) coordinates, the vectors must be rotated according to vectors need to be rotated according to</p> $$ \\begin{equation} \\begin{array}{ll} U^{'}(x*{t}^{'},y*{t}^{'}) = U(x*{t},y*{t})_cos(\\alpha_{t}) - V(x*{t},y\\_{t})*sin(\\alpha*{t}) \\\\ V^{'}(x*{t}^{'},y*{t}^{'}) = U(x*{t},y*{t})\\*sin(\\alpha*{t}) + V(x*{t},y*{t})\\*cos(\\alpha\\_{t}) \\end{array} \\end{equation}  $$  <p>For parent models with rotated rectangle grids, the angle is almost constant. For those with curvilinear tripolar grids (as shown in Fig. 2.6(a)) the angle will vary within each grid cell.</p> (A) (B) Example of curvilinear grid. Panel A gives an example of a tripolar grid. Panel B gives the horizontal velocity components defined on the source curvilinear grid (black arrows) and on the destination rectilinear lat/lon grid (red arrows) after the rotation."},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#extrapolation-methods","title":"Extrapolation methods","text":"<p>The extrapolation procedure used in SURF is referred to as the sea-over-land (SOL) procedure, and provides the ocean field values for areas near the coastline where the parent model solutions are not defined. The SOL procedure iteratively extrapolates the ocean quantities on the land grid-points, so they can be interpolated on the child grid. This also applies to several atmospheric fields and takes into account the atmospheric land-sea mask, to avoid land contaminations near the land-sea boundaries.</p> <p>The SOL procedure is applied to the coarse resolution ocean fields to extrapolate the salinity, temperature, sea surface height and current fields to the land points. The ocean fields in the nested-grid points near to the coast can then be defined (by interpolation). The procedure applied for the atmospheric forcing fields takes into account the atmospheric land-sea mask to ensure there is no contamination from the land atmospheric fields to the sea points.</p> <p>The source code is provided in the directory <code>$PATH_SURFNEMO/utilities/extrapol/seaoverland</code>.</p>"},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#interpolation-methods","title":"Interpolation methods","text":"<p>The extrapolation procedure described in the previous section provides the input data for the interpolator. The procedures are based on the Spherical Coordinate Remapping and Interpolation Package (SCRIP) code. SCRIP is a software package that computes addresses and weights for remapping and interpolating fields between grids in spherical coordinates. The package should work for any grid on the surface of a sphere. SCRIP currently supports five remapping options:</p> <ul> <li><p>Conservative remapping: First- and second-order conservative remapping, as described by Jones (1999, Monthly Weather Review, 127, 2204-2210).</p></li> <li><p>Bilinear interpolation: Slightly generalized to use a local bilinear approximation (only logically rectangular grids).</p></li> <li><p>Bicubic interpolation: Similarly generalized (only logically rectangular grids).</p></li> <li><p>Distance-weighted averaging: The inverse-distance-weighted average of a user-specified number of nearest neighbour values.</p></li> <li><p>Particle remapping: A conservative particle (Monte-Carlo-like) remapping scheme</p></li> </ul> <p>The source code can be found in the directory <code>$PATH_SURFNEMO/nemo/NEMOGCM/TOOLS/WEIGHTS</code>.</p> <p>Regridding can be separated into two stages. The first stage is the generation of an interpolation weight matrix that describes how points in the source grid contribute to points in the destination grid. The second stage is the multiplication of values on the source grid by the interpolation weight matrix to produce the appropriate values on the destination grid.</p> <p>The SCRIP spatial interpolation procedure is applied to the input fields for the generated bathymetry, atmospheric forcing and initial and boundary conditions files that are necessary to run the NEMO code. The generated files are stored in the directory <code>$PATH_EXP/IDEXP/data/</code>.</p>"},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#lateral-open-boundary-condition","title":"Lateral Open Boundary Condition","text":"<p>The lateral open boundary condition for the selected nested-domain is implemented using the BDY module of NEMO. Two numerical algorithms are used to treat open boundary conditions depending on the prognostic simulated variables. The Flather scheme (Oddo and Pinardi, 2008) is used for barotropic velocities, while the flow relaxation scheme (Engerdahl, 1995) is considered for baroclinic velocities, active tracers and sea surface height. In our formulation, we provide external data along straight open boundary lines, and the relaxation area is equal to one internal grid point. As the parent coarse resolution ocean model provides only the total velocity field, the interpolated total velocity field in the child grid is split into barotropic and baroclinic components. An integral constraint method is imposed to preserve the total transport after the interpolation.</p> <p>This process involves the following steps: (1) defining the open boundary geometry (for each of the T, U and V grids) and physical fields (active tracers, sea-surface height, barotropic and baroclinic velocities) at the open boundary points using the geometry_bdy and fields_bdy procedures, respectively; (2) writing these data arrays to the files that are necessary to run the NEMO code. The algorithms used for the different fields are the Flather radiation scheme for the barotropic velocities and the sea surface height and the Flow relaxation scheme for the baroclinic velocities and active tracers. The generated files are stored in the directory <code>$PATH_EXP/IDEXP/data/</code>.</p>"},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#integral-constraint-at-the-open-boundary","title":"Integral Constraint at the open boundary","text":"<p>The downscaling is designed to ensure that the volume transport across the open boundary (OB) of the child model matches that across the corresponding section of the parent model. At the eastern/western boundaries U-Points are imposed using the following conditions  $$  \\begin{equation} \\begin{array}{ll} \\int*{y_2}^{y_1} \\int*{-H*{child}}^{\\eta*{child}} U*{child} dz dy = \\int*{y*2}^{y_1} \\int*{-H*{parent}}^{\\eta*{parent}} U\\_{parent} dz dy \\end{array} \\end{equation}  $$  where \\(y_1, y_2\\) are the extremes of the open boundary section; \\(\\eta_{child}, H_{child}\\) are the surface elevation and the bathymetry of the child model at the boundary, respectively; \\(\\eta_{parent}, H_{parent}\\) are the surface elevation and the bathymetry of the parent model at the boundary, respectively; and \\(U_{parent},U_{child}\\) are the parent/child total zonal velocities (normal velocity to the W/E boundaries). The corrected velocity component normal to the boundary \\(V_{child}\\) is given (see N. Pinardi et al., 2003) by:  $$  \\begin{equation} \\begin{array}{ll} U*{child} (x,y,z,t) = U*{interp} - U\\_{correction} \\end{array} \\end{equation}  $$  where \\(U_{interp}\\) is the \\(U_{parent}\\) interpolated on the child open boundary points and the velocity correction is given by  $$  \\begin{equation} \\begin{array}{ll} U*{correction} = \\frac{M*{interp} - M\\_{parent}}{S} \\end{array} \\end{equation}  $$  where \\( M_{interp} = \\int_{y_2}^{y_1} \\int_{-H_{child}}^{\\eta_{child}} U_{interp} dz dy \\) is the volume transport across the OB, the \\( M_{parent} = \\int_{y_2}^{y_1} \\int_{-H_{parent}}^{\\eta_{parent}} U_{parent} dz dy \\) is the volume transport across the corresponding OB and \\( S = \\int_{y_2}^{y_1} \\int_{-H_{child}}^{\\eta_{child}} dz dy \\) is the area of the section. These conditions are similarly imposed for the meridional velocity at the northern/southern boundaries (V-Points). The Integral Constraint procedure ensures that the interpolation does not modify the net transport across the child model lateral open boundary."},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#model-run","title":"Model run","text":"<p>Finally, the NEMO code is numerically integrated by the SURF platform. The output files are continuously updated, given a fixed output frequency, throughout the execution of the program. The logfile is a text file NEMO produces that contains data on how far the run has advanced by providing the time step. After the model run is completed, the output files are stored in the experiment directory <code>$PATH_IDEXP/data/data00/outdata/</code> (see appendix B).</p>"},{"location":"ch2_work-flow-of-the-SURF-NEMO-platform/#post-processing","title":"Post-processing","text":"<p>In this step the visualization and analysis procedures of the forecast are considered. These can be activated after the execution of each macro-task. The user can visualize the input, regridded and output datasets, compare parent/child fields and convert the model output datasets.</p> <p>$$</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/","title":"User Configuration File - Preprocessing Sections","text":"To execute the SURF-NEMO package, the user must input several model parameters to select a specific simulation region, the simulation period, horizontal and vertical turbulence schemes, input datasets, interpolation methods, etc. These parameters are used to conduct the pre- and post-processing phases and to populate the Fortran namelist required to execute the NEMO-OPA code. These choices are made by specifying the values of the input model parameters in the user configuration file \"<code>setParFree.json</code>\", where all the free-user input parameters are grouped in different sections according to their functionality. In this chapter we provide details of each section of the configuration file and specify the admissible values, the unit measures and the \u201creference value\u201d used for the test case experiment for each parameter (see Section 6.4). Some of the input model parameters are fixed and defined inside the SURF source package in the file \"<code>setParFix</code>\" (see Appendix A for more details)"},{"location":"ch3_user-configuration-file-preprocessing-sections/#configuration-file-and-json-object-structure","title":"Configuration file and JSON Object Structure","text":"The user configuration file has a JavaScript Object Notation (JSON)-based format. JSON is a simple, text-based method of storing and transmitting structured data. This format is \"self-describing\", easy to understand and can support complex data types and structures. It is commonly used for configuration files in web applications. JSON syntax is derived from JavaScript object notation syntax and can contain either an array of values or an object (an associative array of name/value pairs also referred to as properties). An array is surrounded by square brackets, [ and ], and contains a comma-separated list of values. An object is surrounded by curly brackets,{ and }, and contains a comma-separated list of name/value pairs. A name/value pair consists of a field name (in double quotes), followed by a colon (:), followed by the field value. A value in an array or object can be of type number (integer or floating-point), string (in double-quotes), boolean (true or false), another array (surrounded by square brackets, [ and ]), another object (surrounded by curly brackets, and ), or null. The JSON configuration file defined for the SURF-NEMO package is shown in Figure 3.1. At the top level, we have created the \u201csections\u201d array, which is an object with just one name/value pair. This array contains various objects. Each object contains three properties: a title that reflects the contents of the section, a four-digit alphanumeric identifier ID (id = A001, A002, etc. for pre-processing sections and id = B001, B002, etc. for post-processing sections) and an array of items delimited by square brackets. Each element of the \u201citems\u201d array is an object that is identified by a name, a value, a data type (int, float, double, bool and string) and a brief description of the corresponding parameter.   JSON representation for the SURF-NEMO user-configuration file."},{"location":"ch3_user-configuration-file-preprocessing-sections/#genearal-input-parameters","title":"Genearal Input parameters","text":""},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_surf","title":"Section set_surf","text":"<p>The section set_surf contains the following two parameters:</p> <code>nnest</code> <p>Number of nesting domain.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 1 \u00a0 <code>Range</code>: 1, 2, 3</p> <code>nameNestDomain</code> <p>Name of the nest domain to simulate.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: gulfTaranto</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_lrun","title":"Section set_lrun","text":"<p>The section set_lrun contains the logical parameters to activate/deactivate specific tasks.</p> <code>lrun_childMeshMask</code> <p>Enables the execution of the CHILD-MESHMASK GENERATION task.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lrun_regridPreAtm</code> <p>Enables the execution of the ATMOSPHERIC-DATA-REGRIDDING task.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lrun_regridPreOceIC</code> <p>Enables the execution of the OCEAN-IC-DATA-REGRIDDING phase.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lrun_regridPreOceBC</code> <p>Enables the execution of the OCEAN-BC-DATA-REGRIDDING phase.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lrun_regridPreTideBC</code> <p>Enables the execution of the TIDE-BC-DATA-REGRIDDING phase.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lrun_regridPreWeights</code> <p>Enables the computation/copy of WEIGHT-FILEs for input_fields REMAPPING (if lrun_regridPre=True).</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lrun_ocean</code> <p>Enables the execution of the NEMO codes.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lrun_regridOutUV</code> <p>Enables the execution of the output-UV_fields REMAPPING (from UV GRID to T-GRID).</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p> <code>lrun_regridOutUVWeghts</code> <p>Enables the computation/copy of WHEGHT-FILEs for output-UV_fields REMAPPING (if lrun_regridOutUV-True).</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p> <code>lrun_shapFiltBat</code> <p>Enables the execution of the SHAPIRO Filter for Bathymetric datasets.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lrun_shapFiltOce</code> <p>Enable the execution of the SHAPIRO Filter fo Ocean datasets.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#input-parameters-for-spatial-grid-generation","title":"Input parameters for spatial grid generation","text":""},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_xygrid","title":"Section set_xyGrid","text":"<p>The section set_xyGrid contains the free input parameters required for the generation of the horizontal model grid.</p> <code>gr_xygridSpec</code> <p>Parameters specification for the horizontal grid: if = 0, the grid is function of the 5 variables (lam0,phi0,nlam,nphi,dxy) if = 1, the grid is function of the 5 variables (lam0,phi0,lam1,phi1,dxy)..</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 0 \u00a0 <code>Range</code>: 0, 1</p> <code>gr_jpidta</code> <p>Number of grid points in zonal direction to specify if xygridSpec=0 (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 94</p> <code>gr_jpjdta</code> <p>Number of grid points in meridional direction to specify if xygridSpec=0 (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 79</p> <code>gr_ppglam0</code> <p>Longitude of the first raw and column T-point to specify if xygridSpec=0,1.</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 16.4375</p> <code>gr_ppglam1</code> <p>Longitude of the last raw and column T-point to specify if xygridSpec=1 (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>gr_ppgphi0</code> <p>Latitude of the first raw and column T-point to specify if xygridSpec=0,1.</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 38.9375</p> <code>gr_ppgphi1</code> <p>Latitude of the last raw and column T-point to specify if xygridSpec=1 (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>gr_jp_cfg</code> <p>Child model resolution (1/gr_jp_cfg) to specify if xygridSpec=0,1.</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 48.</p> <code>gr_jp_cfg_father</code> <p>Father model resolution (1/gr_jp_cfg_father).</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 16.</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_zgrid","title":"Section set_zGrid","text":"<p>The section set_zGrid contains the free input parameters used to generate the vertical grid.</p> <code>gr_jpkdta</code> <p>Number of vertical levels.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 120</p> <code>gr_zgridSpec</code> <p>Parameters specification for the vertical grid: if = 0, the grid is function of the 5 variables (hh0,h1,hsur,hcr,hth) if = 1, the grid is function of the 4 variables (dzmin,hmax,hcr,hth).</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 1. \u00a0 <code>Range</code>: 0, 1</p> <code>gr_ppsur</code> <p>Parameter h_sur for the z-coord. trasformation to specify if zgridSpec=0 (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: double \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>gr_ppa0</code> <p>Parameter h_0 for the z-coordinate trasformation to specify if zgridSpec=0 (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: double \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>gr_ppa1</code> <p>Parameter h_1 for the z-coordinate trasformation to specify if zgridSpec=0 (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: double \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>gr_ppkth</code> <p>Parameter h_th which gives the approximate layer number above which stretching will be maximum (usually of order nz/2) to specify if zgridSpec=0,1.</p> <p><code>Type</code>: double \u00a0 <code>Ref.Value</code>: 100</p> <code>gr_ppacr</code> <p>Parameter h_cr which gives the grid stretching factor (the highest gr_ppacr, the smallest the stretching) to specify if zgridSpec=0,1.</p> <p><code>Type</code>: double \u00a0 <code>Ref.Value</code>: 30</p> <code>gr_ppdzminw</code> <p>Depth of the top (first) model layer depth of second 'w' level to specify if zgridSpec=1 (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: double \u00a0 <code>Ref.Value</code>: 2.8</p> <code>gr_pphmaxw</code> <p>Maximum depth of the ocean depth of the last 'w' level (set to 0.0 to be computed) to specify if zgridSpec=1 (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: double \u00a0 <code>Ref.Value</code>: 0.0</p> <code>gr_dbletanh</code> <p>Enables the use of the double tanh function for vertical coordinates.</p> <p><code>Type</code>: bool. \u00a0 <code>Ref.Value</code>: False.</p> <code>gr_ppa2</code> <p>Parameter h_2 to specify if gr_dbletanh=True (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: double \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>gr_ppkth2</code> <p>Parameter h_th2 if gr_dbletanh=True (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: double \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>gr_ppacr2</code> <p>Parameter h_cr2 if gr_dbletanh=True (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: double \u00a0 <code>Ref.Value</code>: NOTUSED</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#input-parameters-for-date-and-time-simulation","title":"Input parameters for date and time simulation","text":""},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_datetime","title":"Section set_dateTime","text":"<p>This section of the JSON file contains the free input parameters used to define the period and time discretization of the simulation.</p> <code>start_date</code> <p>Initial date of the simulation (the run starts at 00:00).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: 20141005</p> <code>ndays</code> <p>Total number of simulation days.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 2</p> <code>ndays_spinup</code> <p>Number of spin-up days.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 1 \u00a0 <code>Range</code>: 0:ndays</p> <code>dom_rdt</code> <p>Simulation 'baroclinic' time step (...40, 48, 50, 60, 72, 80, 90, 100, 120, 144...).</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 150.</p> <code>runMan_write</code> <p>Frequency of write in the output file express as the number of simulation time step.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 24</p> <code>dom_btAuto</code> <p>Enables the automatically definition of baro-timestep to be just below a user defined maximum courant number dom_btCmax.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p> <code>dom_btCmax</code> <p>Maximum courant number (allowed if dom_btAuto=True).</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 0.8</p> <code>dom_baro</code> <p>Number of iterations of barotropic mode during dom_rdt (allowed if dom_btAuto=False).</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 100</p> <code>runMan_rstart</code> <p>Start from rest (False) or from a restart file (True).</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>ndays_xsimu</code> <p>Number of days per each restart simulation.</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 1</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#input-parameters-for-surface-and-lateral-boundary-conditions","title":"Input parameters for surface and lateral boundary conditions","text":""},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_sbc","title":"Section set_sbc","text":"<p>This section of the JSON file contains the free input parameters used to define surface boundary condition.</p> <code>sbc_iformulat</code> <p>Surface boundary condition formulation to be used (=0)MFS bulk formulat,(=1)fluxform+ssRest,(=2)CORE formulation.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 0 \u00a0 <code>Range</code>: 0, 1, 2</p> <code>sbc_ltimeInterp</code> <p>Activate, or not, the time interpolation (=False) steplike shape forcing (=True) broken line shape forcing.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>sbc_zreftemp</code> <p>Reference height (m) for the Air Temperature and humidity (for the CORE formulation).</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 10.</p> <code>sbc_zrefwind</code> <p>Reference height (m) for the wind vector (for the CORE formulation).</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 10.</p> <code>sbc_aprdyn</code> <p>Enables the inclusion of atmospheric pressure gradien in ocean and ice Eqs..</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p> <code>sbc_sclapr</code> <p>Scaling factor to convert atmospheric presure from hPa to Pa.</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 1.</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_obc","title":"Section set_obc","text":"<p>This section of the JSON file contains the free input parameters used to define lateral open boundary conditions.</p> <code>obc_dyn2d</code> <p>Algorithm of boundary condition for barotropic solution: flather.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: flather \u00a0 <code>Range</code>: flather</p> <code>obc_dyn2d_dta</code> <p>Boundary data to use: (=0)Initial condition (=1)external data (=2)tidal forcing (=3)xternal data+tidal.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 1 \u00a0 <code>Range</code>: 0, 1, 2 ,3</p> <code>obc_dyn3d</code> <p>Algorithm of boundary condition for baroclinic velocities: frs, orlanski.</p> <p><code>Type</code>: string  \u00a0 <code>Ref.Value</code>: frs \u00a0 <code>Range</code>: frs, orlanski</p> <code>obc_dyn3d_dta</code> <p>Boundary data to use: (=0)Initial condition (=1)external data.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 1 \u00a0 <code>Range</code>: 0, 1</p> <code>obc_tra</code> <p>Algorithm of boundary condition for active tracers: frs, orlanski.</p> <p><code>Type</code>: string  \u00a0 <code>Ref.Value</code>: frs \u00a0 <code>Range</code>: frs, orlanski</p> <code>obc_tra_dta</code> <p>Boundary data to use: (=0)Initial condition (=1)external data.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 1 \u00a0 <code>Range</code>: 0, 1</p> <code>obc_rimwidth</code> <p>Width of the FRS zone.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 1</p> <code>obc_ltimeInterp</code> <p>Activate, or not, the time interpolation (=False) steplike shape forcing (=True) broken line shape forcing.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>obc_lvelCorr</code> <p>Activate the Integral Contraint method to preserve the total transport after the interpolation.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_tide","title":"Section set_tide","text":"<p>This section of the JSON file contains the free input parameters used to define the tidal components which can be added both as the equilibrium tidal sea level and/or only at the lateral boundaries</p> <code>latBtide_lPot</code> <p>Enables the use of tidal potential forcing.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>latBtide_K1</code> <p>Name of the Lunar diurnal K1 tidal component (if =NOTUSED, component not used).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: K1 \u00a0 <code>Range</code>: K1</p> <code>latBtide_O1</code> <p>Name of the Lunar diurnal O1 tidal component (if =NOTUSED, component not used).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: O1 \u00a0 <code>Range</code>: O1</p> <code>latBtide_P1</code> <p>Name of the Solar diurnal P1 tidal component (if =NOTUSED, component not used).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: P1 \u00a0 <code>Range</code>: P1</p> <code>latBtide_Q1</code> <p>Name of the Larger lunar elliptic diurnal Q1 tidal component (if =NOTUSED, component not used).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: Q1 \u00a0 <code>Range</code>: Q1</p> <code>latBtide_K2</code> <p>Name of the Lunisolar semidiurnal K2 tidal component (if =NOTUSED, component not used)</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: K2 \u00a0 <code>Range</code>: K2</p> <code>latBtide_M2</code> <p>Name of the Principal lunar semidiurnal M2 tidal component (if =NOTUSED, component not used).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: M2 \u00a0 <code>Range</code>: M2</p> <code>latBtide_N2</code> <p>Name of the Larger lunar elliptic semidiurnal N2 tidal component (if =NOTUSED, component not used).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: N2 \u00a0 <code>Range</code>: N2</p> <code>latBtide_S2</code> <p>Name of the Principal solar semidiurnal S2 tidal component (if =NOTUSED, component not used).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: S2 \u00a0 <code>Range</code>: S2</p> <code>latBtide_M4</code> <p>Name of the Shallow water overtides of principal lunar M4 tidal component (if =NOTUSED, component not used).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: M4 \u00a0 <code>Range</code>: M4</p> <code>latBtide_Mm</code> <p>Name of the Lunar monthly Mm tidal component (if =NOTUSED, component not used).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: Mm \u00a0 <code>Range</code>: Mm</p> <code>latBtide_Mf</code> <p>Name of the Lunisolar fortnightly Mf tidal component (if =NOTUSED, component not used).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: Mf \u00a0 <code>Range</code>: Mf</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#input-parameters-for-physical-parametrization","title":"Input parameters for physical parametrization","text":""},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_eos","title":"Section set_eos","text":"<p>This section of the JSON file contains the free input parameters used to define equation of state of sea water.</p> <code>eos_type</code> <p>type of equation of state and Brunt-Vaisala frequency: (=-1)TEOS-10, (=0)EOS-80, (=1)S-EOS.</p> <p><code>Type: int</code> <code>Ref.Value</code>: 0 \u00a0 <code>Range</code>: -1, 0, 1</p> <code>eos_useCT</code> <p>Enables the use of Conservative Temp. ==&gt; surface CT converted in Pot. Temp. in sbcssm.</p> <p><code>Type: bool</code> <code>Ref.Value</code>: False</p> <code>eos_a0</code> <p>S-EOS coefficients: thermal expension coefficient.</p> <p><code>Type: float</code> <code>Ref.Value</code>: 0.1655</p> <code>eos_b0</code> <p>S-EOS coefficients: saline expension coefficient.</p> <p><code>Type: float</code> <code>Ref.Value</code>: 0.76554</p> <code>eos_lambda1</code> <p>S-EOS coefficients: cabbeling coeff in T^2  (=0 for linear eos).</p> <p><code>Type: float</code> <code>Ref.Value</code>: 0.05952</p> <code>eos_lambda2</code> <p>S-EOS coefficients: cabbeling coeff in S^2  (=0 for linear eos).</p> <p><code>Type: float</code> <code>Ref.Value</code>: 0.00074914</p> <code>eos_mu1</code> <p>S-EOS coefficients: thermobaric coeff. in T (=0 for linear eos).</p> <p><code>Type: float</code> <code>Ref.Value</code>: 0.0001497</p> <code>eos_mu2</code> <p>S-EOS coefficients: thermobaric coeff. in S (=0 for linear eos).</p> <p><code>Type: float</code> <code>Ref.Value</code>: 1.109e-05</p> <code>eos_nu</code> <p>S-EOS coefficients: cabbeling coeff in T*S  (=0 for linear eos).</p> <p><code>Type: float</code> <code>Ref.Value</code>: 0.0024341</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_botfric","title":"Section set_botFric","text":"<p>This section of the JSON file contains the free input parameters used to define the bottom friction</p> <code>botB_bfri2</code> <p>Bottom drag coefficient (non linear case).</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 1.e-3</p> <code>botB_bfeb2</code> <p>Bottom turbulent kinetic energy background (m^2/s^2).</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 2.5e-3</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_xyturbtracers","title":"Section set_xyturbTracers","text":"<p>This section of the JSON file contains the free input parameters used to define the parameterization of lateral subgrid-scale diffusion for tracers. </p> <code>tra_typeOperator</code> <p>Type of the operator used (0)laplacian, (1)bilaplacian.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 0 \u00a0 <code>Range</code>: 0, 1</p> <code>tra_eddycoeffSpec</code> <p>Horizontal eddy coeff. specification (0)def. by coeff. tra_eddycoeff_child, (1)def. from coeff. tra_eddycoeff_father according fat/child coeff. relation.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 0 \u00a0 <code>Range</code>: 0, 1</p> <code>tra_eddycoeff_child</code> <p>Horizontal eddy diffusivity (&gt;0 (m2/s) laplacian or &lt; 0 (m4/s2) bilaplacian) of the child model (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 80.</p> <code>tra_eddycoeff_father</code> <p>Horizontal eddy diffusivity (&gt;0 (m2/s) laplacian or &lt; 0 (m4/s2) bilaplacian) of the father model to be used in fat/child coeff. relation (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>tra_factor</code> <p>Factor to be used in fat/child coeff. relation (if laplacian:(a_child=factor*???), if bilaplacian:(a_child=factor*a_fat(Dx_child/Dx_fat)^4)).</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 1</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_xyturbmomentum","title":"Section set_xyturbMomentum","text":"<p>This section of the JSON file contains the free input parameters used to define the parameterization of lateral subgrid-scale viscosity for momentum. </p> <code>dyn_typeOperator</code> <p>type of the operator used (0)laplacian, (1)bilaplacian.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 1 \u00a0 <code>Range</code>: 0, 1</p> <code>dyn_eddycoeffSpec</code> <p>horizontal eddy coeff. specification (0)def. by coeff. dyn_eddycoeff_child, (1)def. from coeff. dyn_eddycoeff_father according fat/chld coeff. relation.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 1 \u00a0 <code>Range</code>: 0, 1</p> <code>dyn_eddycoeff_child</code> <p>horizontal eddy viscosity (&gt;0 (m2/s) laplacian or &lt; 0 (m4/s2) bilaplacian) of the child model (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>dyn_eddycoeff_father</code> <p>horizontal eddy viscosity (&gt;0 (m2/s) laplacian or &lt; 0 (m4/s2) bilaplacian) of the father model to be used in fat/child coeff. relation (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: -0.5e10</p> <code>dyn_factor</code> <p>factor to be used in father/child coeff. relation (if laplacian:(a_child=factor*???), if bilaplacian:(a_child=factor*a_fat(Dx_child/Dx_fat)^4)).</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 1.</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_zturb","title":"Section set_zturb","text":"<p>This section of the JSON file contains the free input parameters used to define the vertical eddy viscosity and diffusivity coefficients</p> <code>zdyn_avm0</code> <p>Vertical eddy viscosity [m2/s] (background Kz if not 'key_zdfcst').</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 1.2e-5</p> <code>zdyn_avt0</code> <p>Vertical eddy diffusivity [m2/s] (background Kz if not 'key_zdfcst').</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 1.2e-6</p> <code>zdyn_avevd</code> <p>Evd mixing coefficient [m2/s].</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 10.</p> <code>zdynric_avmri</code> <p>Maximum value of the vertical viscosity.</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 1.e-2</p> <code>zdynric_alp</code> <p>Vertical eddy viscosity [m2/s] (background Kz if not 'key_zdfcst').</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 5.</p> <code>zdynric_ric</code> <p>Vertical eddy viscosity [m2/s] (background Kz if not 'key_zdfcst').</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 2.</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#input-parameters-for-downloading-input-datasets","title":"Input parameters for downloading input datasets","text":""},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_datadownlcoast_urlname","title":"Section set_dataDownlCoast_urlName","text":"<p>This section of the JSON file contains the parameters needed to make up the URL that is required to access the input coastline datasets from a local or remote ropository.</p> <code>urlCoast_usr</code> <p>Username to access the coastline datasets from a remote ftp server.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: usr</p> <code>urlCoast_pwd</code> <p>Password to access the coastline datasets from a remote ftp server.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: pwd</p> <code>urlCoast_urlbase</code> <p>Parametric urlname (i.e. ftp:/... or file:///...) for the coastline datasets. Parameters: (RESCOAST).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: file:///scratch/surf/surf_datasets/current/coastline/GSHHS_shp/(RESCOAST)</p> <code>urlCoast_resol</code> <p>Name for spatial resolution used to replace the substring (RESCOAST) on the parametric urlname (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: h \u00a0 <code>Range</code>: f, h, i, l, c</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_datadownlcoast_filename","title":"Section set_dataDownlCoast_fileName","text":"<p>This section of the JSON file contains the parameters for the FILENAMEs of the input coastline datasets.</p> <code>fileCoast_lland</code> <p>Enables the use of the land coastline.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>fileCoast_filebaseLand</code> <p>Files name for NOAA coastline datasets contains boundary between land and ocean (if fileCoast_lland=True). Parameters: (RESCOAST).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: GSHHS_(RESCOAST)_L1.shp</p> <code>fileCoast_llake</code> <p>Enables the use of the lake coastline.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p> <code>fileCoast_filebaseLake</code> <p>Files name for NOAA coastline datasets contains boundary between lake and land (if fileCoast_llake=True). Parameters: (RESCOAST).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: GSHHS_(RESCOAST)_L2.shp</p> <code>fileCoast_lislandlake</code> <p>Enables the use of the islelake coastline.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p> <code>fileCoast_filebaseIslandlake</code> <p>Files name for NOAA coastline datasets contains boundary between island-in-lake and lake (if fileCoast_lislandlake=True). Parameters: (RESCOAST).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: GSHHS_(RESCOAST)_L3.shp</p> <code>fileCoast_resol</code> <p>Name for spatial resolution used to replace the substring (RESCOAST) on the parametric file name (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: h</p> <code>fileCoast_lcompression</code> <p>(=True) if datasets you want to download are gzip compressed files (*.gz).</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p> <code>fileCoast_lkeepSrcFull</code> <p>(=True) if you want to keep in your disk the downloaded uncutted datasets.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_datadownlbat_urlname","title":"Section set_dataDownlBat_urlName","text":"<p>This section of the JSON file contains the parameters needed to make up the URL that is required to access the input bathymetry datasets from a local or remote ropository.</p> <code>urlBat_usr</code> <p>Username to access the bathymetric datasets from a remote ftp server.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: usr</p> <code>urlBat_pwd</code> <p>Password to access the bathymetric datasets from a remote ftp server.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: pwd</p> <code>urlBat_urlbase</code> <p>Parametric urlname (i.e. ftp:/... or file:///...) for the bathymetric datasets. Parameters: (RESOL).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: usr</p> <code>urlBat_resol</code> <p>Name for spatial resolution used to replace the substring (RESOL) on the parametric urlname (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: h</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_datadownlbat_filename","title":"Section set_dataDownlBat_fileName","text":"<p>This section of the JSON file contains the parameters for the FILENAME of the input bathymetry datasets.</p> <code>fileBat_filebase</code> <p>Parametric filename for the source bathymetric datasets. Parameters: (RESBAT).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: macroMED_bathyGEBCO.nc</p> <code>fileBat_resol</code> <p>Name for spatial resolution used to replace the substring (RESBAT) on the parametric file name (if =NOTUSED, parameter not read).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>fileBat_lcompression</code> <p>(=True) if datasets you want to download are gzip compressed files (*.gz).</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p> <code>fileBat_llonFlip</code> <p>(=True) if longitude coord. is in the 0 to 360 range and (=False) if longitude is in -180:+180 range.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: macroMED_bathyGEBCO.nc</p> <code>fileBat_llatInv</code> <p>(=True) if the dataset contains latitude decreasing through the pole.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p> <code>fileBat_ldepthIncr</code> <p>(=True) if the dataset contains sea floor elevation (positive) increases with increasing water depth.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p> <code>fileBat_lkeepSrcFull</code> <p>(=True) if you want to keep in your disk the downloaded uncutted datasets.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_datadownlbat_varname","title":"Section set_dataDownlBat_varName","text":"<p>This section of the JSON file contains the parameters for the VARIABLE-NAMEs of the input bathymetry datasets.</p> <code>srcDimBat_lon</code> <p>Name of the dimension for the longitude.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: lon</p> <code>srcDimBat_lat</code> <p>Name of the dimension for the latitude.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: lat</p> <code>srcCrdBat_lon</code> <p>Name of the coordinate variable for the longitude.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: lon</p> <code>srcCrdBat_lat</code> <p>Name of the coordinate variable for the latitude.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: lat</p> <code>srcVarBat_elev</code> <p>Name of the variable for the Sea Floor Elevation.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: elevation</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_datadownlatmmesh_urlname","title":"Section set_dataDownlAtmMesh_urlName","text":"<p>This section of the JSON file contains the parameters needed to make up the URL that is required to access the input atmospheric meshmask datasets from a local or remote ropository.</p> <code>urlAtmMesh_usr</code> <p>Username to access the input atmospheric meshmask datasets from a remote ftp server.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: usr</p> <code>urlAtmMesh_pwd</code> <p>Password to access the input atmospheric meshmask datasets from a remote ftp server.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: pwd</p> <code>urlAtmMesh_urlbase</code> <p>Parametric urlname (i.e. ftp:/... or file:///...) for input atmospheric meshmask datasets. Parameters: (FIELD),YYYY(p)MM(p)DD(p).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: file:///scratch/surf/indata_offline/gulfTaranto_20141005/data/data00/indata/atmosphere/srcFull</p> <code>urlAtmMesh_velU</code> <p>Name for the Zonal Air Velocity used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: v10m</p> <code>urlAtmMesh_velV</code> <p>Name for the Meridional Air Velocity used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: v10m</p> <code>urlAtmMesh_mslp</code> <p>Name for the Mean Sea-Level Pressure used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: mslp</p> <code>urlAtmMesh_cloudCov</code> <p>Name for the Total Cloud Cover used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: tcc</p> <code>urlAtmMesh_temp</code> <p>Name for the Air Temperature used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: t2m</p> <code>urlAtmMesh_dpTemp</code> <p>\"Name for the Dewpoint Temperature used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: d2m</p> <code>urlAtmMesh_prec</code> <p>Name for the Total Precipitation used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: precip</p> <code>urlAtmMesh_tauU</code> <p>Name for the Zonal Wind Stress used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: tauU</p> <code>urlAtmMesh_tauV</code> <p>Name for the Meridional Wind Stress used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: tauV</p> <code>urlAtmMesh_qtot</code> <p>Name for the Total Heat Flux used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: qtot</p> <code>urlAtmMesh_qsr</code> <p>Name for the Solar Radiation Penetration used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: qsr</p> <code>urlAtmMesh_emp</code> <p>Name for the Mass Flux Exchanged used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: emp</p> <code>urlAtmMesh_tempS</code> <p>Name for the Surface Temperature used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: sst</p> <code>urlAtmMesh_salS</code> <p>Name for the Surface Salinity used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: sss</p> <code>urlAtmMesh_umid</code> <p>Name for the Air Umidity used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: umid</p> <code>urlAtmMesh_radLW</code> <p>Name for the Long Wave Radiation used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: lwrd</p> <code>urlAtmMesh_radSW</code> <p>Name for the Short Wave Radiation used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: swrd</p> <code>urlAtmMesh_snow</code> <p>Name for the Solid Precipitation used to replace the substring (FIELD) on the parametric urlname.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: snow</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_datadownlatmmesh_filename","title":"Section set_dataDownlAtmMesh_fileName","text":"<p>This section of the JSON file contains the parameters needed to make up the FILENAMEs of the input atmospheric meshmask datasets.</p> <code>fileAtmMesh_filebase_velU</code> <p>Parametric filename for the Zonal Air Velocity datasets before the spinup-time (if sbc_iformulat=0,2). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: YYYY(i)MM(i)DD(i)-ECMWF---AM0125-MEDATL-bYYYY(i+1)MM(i+1)DD(i+1)_an-fv05.00.nc</p> <code>fileAtmMesh_filebase_velV</code> <p>Parametric filename for the Meridional Air Velocity datasets before the spinup-time (if sbc_iformulat=0,2). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: YYYY(i)MM(i)DD(i)-ECMWF---AM0125-MEDATL-bYYYY(i+1)MM(i+1)DD(i+1)_an-fv05.00.nc</p> <code>fileAtmMesh_filebase_mslp</code> <p>Parametric filename for the Mean Sea-Level Pressure datasets before the spinup-time (if sbc_iformulat=0 or/and sbc_aprdyn). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: YYYY(i)MM(i)DD(i)-ECMWF---AM0125-MEDATL-bYYYY(i+1)MM(i+1)DD(i+1)_an-fv05.00.nc</p> <code>fileAtmMesh_filebase_cloudCov</code> <p>Parametric filename for the Total Cloud Cover datasets before the spinup-time (if sbc_iformulat=0). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: YYYY(i)MM(i)DD(i)-ECMWF---AM0125-MEDATL-bYYYY(i+1)MM(i+1)DD(i+1)_an-fv05.00.nc</p> <code>fileAtmMesh_filebase_temp</code> <p>Parametric filename for the Air Temperature datasets before the spinup-time (if sbc_iformulat=0,2). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: YYYY(i)MM(i)DD(i)-ECMWF---AM0125-MEDATL-bYYYY(i+1)MM(i+1)DD(i+1)_an-fv05.00.nc</p> <code>fileAtmMesh_filebase_dpTemp</code> <p>Parametric filename for the Dewpoint Temperature datasets before the spinup-time (if sbc_iformulat=0). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: YYYY(i)MM(i)DD(i)-ECMWF---AM0125-MEDATL-bYYYY(i+1)MM(i+1)DD(i+1)_an-fv05.00.nc</p> <code>fileAtmMesh_filebase_prec</code> <p>Parametric filename for the Total Precipitation datasets before the spinup-time (if sbc_iformulat=0,2). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: YYYY(i)MM(i)DD(i)_YYYY(i+1)MM(i+1)DD(i+1)-ECMWF---AM025-MEDATL-bYYYY(i)MM(i)DD(i)_fc00-fv02.00_PREC.nc</p> <code>fileAtmMesh_filebase_tauU</code> <p>Parametric filename for the Zonal Wind Stress datasets before the spinup-time (if sbc_iformulat=1). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>fileAtmMesh_filebase_tauV</code> <p>Parametric filename for the Meridional Wind Stress datasets before the spinup-time (if sbc_iformulat=1). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: usr</p> <code>fileAtmMesh_filebase_qtot</code> <p>Parametric filename for the Total Heat Flux datasets before the spinup-time (if sbc_iformulat=1). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: usr</p> <code>fileAtmMesh_filebase_qsr</code> <p>Parametric filename for the Solar Radiation Penetration datasets before the spinup-time (if sbc_iformulat=1). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: usr</p> <code>fileAtmMesh_filebase_emp</code> <p>Parametric filename for the Mass Flux Exchanged datasets before the spinup-time (if sbc_iformulat=1). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: usr</p> <code>fileAtmMesh_filebase_tempS</code> <p>Parametric filename for the Surface Temperature datasets before the spinup-time (if sbc_iformulat=1). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: usr</p> <code>fileAtmMesh_filebase_salS</code> <p>Parametric filename for the Surface Salinity datasets before the spinup-time (if sbc_iformulat=1). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: usr</p> <code>fileAtmMesh_filebase_umid</code> <p>Parametric filename for the Air Umidity datasets before the spinup-time (if sbc_iformulat=1). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: usr</p> <code>fileAtmMesh_filebase_radLW</code> <p>Parametric filename for the Long Wave Radiation datasets before the spinup-time (if sbc_iformulat=1). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: usr</p> <code>fileAtmMesh_filebase_radSW</code> <p>Parametric filename for the Short Wave Radiation datasets before the spinup-time (if sbc_iformulat=1). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: usr</p> <code>fileAtmMesh_filebase_snow</code> <p>Parametric filename for the Solid Precipitation datasets before the spinup-time (if sbc_iformulat=1). Parameters: YYYY(p)MM(p)DD(p),YYYY(i)MM(i)DD(i),YYYY(i-1)MM(i-1)DD(i-1),YYYY(i+1)MM(i+1)DD(i+1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: usr</p> <code>fileAtmMesh_lcompression</code> <p>(=True) if the datasets you want to download are gzip compressed files (*.gz).</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p> <code>fileAtmMesh_llonFlip</code> <p>(=True) if the longitude coord. is in the 0 to 360 range (=False) if longitude is in -180:+180 range.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p> <code>fileAtmMesh_llatInv</code> <p>(=True) if the dataset contains latitude decreasing through the pole.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>fileAtmMesh_lkeepSrcFull</code> <p>(=True) if you want to keep in your disk the downloaded uncutted datasets.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p>"},{"location":"ch3_user-configuration-file-preprocessing-sections/#section-set_datadownlatmmesh_varname","title":"Section set_dataDownlAtmMesh_varName","text":"<p>This section of the JSON file contains the parameters for the VARIABLE-NAMEs of the input atmospheric meshmask datasets.</p> <code>srcDimAtmMesh_lon</code> <p>Name of the dimension for the longitude.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: lon</p> <code>srcDimAtmMesh_lat</code> <p>Name of the dimension for the latitude.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: lat</p> <code>srcDimAtmMesh_time</code> <p>Name of the dimension for the time.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: time</p> <code>srcCrdAtmMesh_lon</code> <p>Name of the coordinate variable containing the longitude.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: lon</p> <code>srcCrdAtmMesh_lat</code> <p>Name of the coordinate variable containing the latitude.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: lat</p> <code>srcCrdAtmMesh_time</code> <p>Name of the variable containing time coordinate.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: time</p> <code>srcVarAtmMesh_mask</code> <p>Name of the variable containing the Land Sea Mask (if sbc_iformulat=0,2).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: LSM</p> <code>srcVarAtmMesh_lont</code> <p>Name of the variable containing longitude coordinate of T-points (if sbc_iformulat=1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>srcVarAtmMesh_lonu</code> <p>Name of the variable containing longitude coordinate of U-points (if sbc_iformulat=1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>srcVarAtmMesh_lonv</code> <p>Name of the variable containing longitude coordinate of V-points (if sbc_iformulat=1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>srcVarAtmMesh_latt</code> <p>Name of the variable containing latitude coordinate of T-points (if sbc_iformulat=1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>srcVarAtmMesh_latu</code> <p>Name of the variable containing latitude coordinate of U-points (if sbc_iformulat=1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>srcVarAtmMesh_latv</code> <p>Name of the variable containing latitude coordinate of V-points (if sbc_iformulat=1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>srcVarAtmMesh_maskt</code> <p>Name of the variable containing the Land Sea Mask of T-points (if sbc_iformulat=1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>srcVarAtmMesh_masku</code> <p>Name of the variable containing the Land Sea Mask of U-points (if sbc_iformulat=1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: NOTUSED</p> <code>srcVarAtmMesh_maskv</code> <p>Name of the variable containing the Land Sea Mask of V-points (if sbc_iformulat=1).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: NOTUSED</p>"},{"location":"ch4_user-configuration-file-postprocessing-sections/","title":"User Configuration File - Postprocessing Sections","text":"<p>In this chapter we continue to explore the contents of the configuration file. In particular we will examine in details the sections B used to manage the post-processing procedures for the visualization of input/output datasets, the comparison of child/parent fields and the comparison of the simulation result with insitu or satellite datasets.</p>"},{"location":"ch4_user-configuration-file-postprocessing-sections/#input-parameters-for-selecting-the-figure-to-generate","title":"Input parameters for selecting the figure to generate","text":""},{"location":"ch4_user-configuration-file-postprocessing-sections/#section-set_lplot","title":"Section set_lplot","text":"<p>The section set_lrun contains the logical parameters to activate/deactivate specific plot.</p> <code>lplot_domain</code> <p>Enable/disable the plotting of the user defined Domains.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplot_indata</code> <p>Enable/disable the plotting of the Input Bat,Atm,OceIC,OceBC data.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplot_extrapdata</code> <p>Enable/disable the plotting of the Extrapolated Atm,OceIC,OceBC data.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplot_intUVdata</code> <p>Enable/disable the plotting of the Interpolated OceIC(U,V),OceBC(U,V) data.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplot_rotUVdata</code> <p>Enable/disable the plotting of the Rotated OceIC(U,V),OceBC(U,V) data.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplot_regriddata</code> <p>Enable/disable the plotting of the Regridded Bat,Atm,OceIC,OceBC,OceBCbdy data.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplot_outdata</code> <p>Enable/disable the plotting of the Output Ocean data.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplot_chlVSpar</code> <p>Enable/disable the plotting of the child VS. parent Ocean fields.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p> <code>lplot_surfVSctd</code> <p>Enable/disable the plotting of the surf VS. ctd Ocean fields.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p> <code>lplot_surfVSmooring</code> <p>Enable/disable the plotting of the surf VS. mooring Ocean fields.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplot_surfVSferrybox</code> <p>Enable/disable the plotting of the surf VS. ferrybox Ocean fields.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p> <code>lplot_surfVSsat</code> <p>Enable/disable the plotting of the surf VS. satellite Ocean fields.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p>"},{"location":"ch4_user-configuration-file-postprocessing-sections/#section-set_visual_lplot","title":"Section set_visual_lplot","text":"<p>The section set_lrun contains the logical parameters to activate/deactivate specific plot.</p> <code>lplotChildMesh</code> <p>Enable/disable the plotting of the Child MeshMask fields.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplotBat</code> <p>Enable/disable the plotting of the Bathymetry fields.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplotAtm</code> <p>Enable/disable the plotting of the Atmspheric fields.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplotOceIC</code> <p>Enable/disable the plotting of the Initial Condition Ocean fields.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplotOceBC</code> <p>Enable/disable the plotting of the Open Boundary Condition Ocean fields.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplotOceBCbdy</code> <p>Enable/disable the plotting of the Open Boundary Condition Ocean fields.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplotTide</code> <p>Enable/disable the plotting of the Tidal fields.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplotTidebdy</code> <p>Enable/disable the plotting of the Tidal fields.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lplotOceOut</code> <p>Enable/disable the plotting of the Output Ocean fields.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: False</p>"},{"location":"ch4_user-configuration-file-postprocessing-sections/#input-parameters-for-figure-properties","title":"Input parameters for figure properties","text":""},{"location":"ch4_user-configuration-file-postprocessing-sections/#section-set_lplot_1","title":"Section set_lplot","text":"<p>The section set_visual_fileImg contains the logical parameters to .</p> <code>fileImg_type</code> <p>Type of the image file to generate.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: png</p> <code>fileImg_wkWidth</code> <p>Horizontal resolution (number of pixels) of the image file.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 2400</p> <code>fileImg_wkHeight</code> <p>Vertical resolution (number of pixels) of the image file.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 2400</p>"},{"location":"ch4_user-configuration-file-postprocessing-sections/#section-set_visual_lvis","title":"Section set_visual_lvis","text":"<p>The section set_visual_lvis contains the logical parameters to .</p> <code>lvis_title</code> <p>Enable/disable the visibility of a given string as the main title.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_mplotDif</code> <p>Enable/disable the plotting of the Bathymetry fields.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_leftString</code> <p>Enable/disable the visibility of a given string above the plot\u2019s upper boundary and left.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_rightString</code> <p>Enable/disable the visibility of a given string above the plot\u2019s upper boundary and right.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_axisLab</code> <p>Enable/disable the visibility of the X an Y axis title.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_tickmarks</code> <p>Enable/disable the visibility of the right, left, top and bottom tick marks.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_borders</code> <p>Enable/disable the visibility of the right, left, top and bottom borders.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_mapFillOn</code> <p>Enable/disable the visibility of the map area fill.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_mapOutlineOn</code> <p>Enable/disable the visibility of the map area outlines.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_vecRefAnnoOn</code> <p>Enable/disable the visibility of the reference vector annotation.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_labbarOn</code> <p>Enable/disable the visibility of the LabelBar.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_labbarLabelsOn</code> <p>Enable/disable the visibility of the LabelBar.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_panelbarOn</code> <p>Enable/disable the visibility of the PannelBar.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_infoContourOn</code> <p>Enable/disable the visibility of the info contour.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_grid</code> <p>Enable/disable the visibility of the mesh grid.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_myCoastline</code> <p>Enable/disable the visibility of the user coastline.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_fillcurves</code> <p>Enables the filling of the area between two curves.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p> <code>lvis_boxNest</code> <p>Enable/disable the visibility of the nest rectangular box.</p> <p><code>Type</code>: bool \u00a0 <code>Ref.Value</code>: True</p>"},{"location":"ch4_user-configuration-file-postprocessing-sections/#section-set_visual_graph","title":"Section set_visual_graph","text":"<p>The section set_visual_graph contains the logical parameters to .</p> <code>graph_projection</code> <p>Projection used for the map transformation. (es. CylindricalEquidistant,Mercator,...).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: Mercator</p> <code>graph_fillMode</code> <p>How ContourPlot performs fill: (=AreaFill), (=RasterFill),(=CellFill).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: AreaFill</p> <code>graph_minDistVec</code> <p>Minimum distance (in NDC space) that is to separate the data locations of neighboring vectors.</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 0.015</p> <code>graph_thickArrowVec</code> <p>Thickness of the line used to draw vector line arrows.</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 2.0</p> <code>graph_refMagnVecAtm</code> <p>Reference magnitude used for the wind vector field.</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 3.0</p> <code>graph_refMagnVecOce</code> <p>Reference magnitude used for the current vector field.</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 0.6</p> <code>graph_styleVec</code> <p>Style of glyph used to represent the vector magnitude and direction: (=LineArrow) ... (=CurlyVector) ....</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: CurlyVector</p> <code>graph_iPlOrient</code> <p>Panels orientation in the multi plots figure: (=0)vertical, (=1)horizontal.</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 1</p> <code>graph_nlevsBar</code> <p>Number of the ....</p> <p><code>Type</code>: int \u00a0 <code>Ref.Value</code>: 21</p> <code>graph_polymarkerSize</code> <p>Size used to draw the marker in the polymarker plots.</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 0.01</p> <code>graph_markLineMode</code> <p>Draw the curves using lines only (=Lines), markers only (=Markers), both lines and markers (=MarkLines).</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: MarkLines</p> <code>graph_lineThick</code> <p>Thickness of the line used to draw the curves.</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 2.5</p> <code>graph_markerSize</code> <p>Size used to draw the marker in the xy-plots.</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 0.01</p> <code>graph_markers</code> <p>Style of the markers in the xy-plots.</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 16</p> <code>graph_boxThick</code> <p>Thickness of the line used to draw the box.</p> <p><code>Type</code>: float \u00a0 <code>Ref.Value</code>: 8.0</p> <code>graph_boxColor</code> <p>Color of the line used to draw the box.</p> <p><code>Type</code>: string \u00a0 <code>Ref.Value</code>: red</p>"},{"location":"ch5_input-output-model-datasets/","title":"Input/Output Model Datasets","text":"In order to execute the SURF-NEMO package, the user has to provide several input datasets. These include the bathymetry datasets containing the seafloor elevation, the coastline datasets delineating borders between land and sea areas, the initial condition dataset containing the initial values of model-predicted variables and the boundary condition datasets containing the values of the variables needed to impose the boundary conditions on flows of mass, momentum and energy for the primitive equation at the surface and lateral open boundaries of the domain. In Figure 5.1 are summarized the interfaces and the external forcings acting on a typical computational domain.   Schematized representation of the interface and external forcing acting on a typical computational domain."},{"location":"ch5_input-output-model-datasets/#input-datasets","title":"Input Datasets","text":"The input model datasets are provided in the classic NetCDF format for bathymetry, initial and lateral boundary condition. NetCDF is a widely used file format in atmospheric and oceanic research which allows storage of different types of array based data, along with a short data description. The coastline datasets are instead provided in Shapefile format, a digital vector data format for geographic information system (GIS) software.  SURF allows also to use, if needed, two different model type of input data during the execution (i.e. analysis data for the spinup time and forecast data after). The user has to set-up few parameters in the configuration file <code> setParFree.json </code> in order to specify the values of path/filename, dimensions/variables name and characteristics of data."},{"location":"ch5_input-output-model-datasets/#bathymetry-dataset","title":"Bathymetry Dataset","text":"The bathymetry dataset contains the sea floor elevation. This dataset is required to generate the child meshmask file. The user needs to set-up the required parameters in the sections <code>set_dataDownlBat</code> of the configuration file. The data are distributed on a curvilinear spherical grid (regular or not) within a region containing the nested domain.             The bathymetry file contains the elevation variable (in meters) at a certain horizontal resolution.          The elevation is relative to a specific reference level and can          increases (positive) or decreases (negative) with increasing water depth.          The coordinate variables (latitude/longitude) can be a one- or two-dimensional array.          An example of CDL text representation of this file is shown in Listing 5.1.     <pre><code>netcdf bathymetry_filename {\ndimensions:\n   x = 300;\n   y = 200;\nvariables: \\\\\n   float lon(y,x);\n      lon: units = \"degrees_east\";\n   float lat(y,x);\n      lat: units = \"degrees_north\";\n   float elevation(y,x);\n      elevation: units = \"m\";\n}\n</code></pre> <p>Listing 5.1: Example of a netCDF file for bathymetry.</p>   The user needs to specify the following logical parameters in section <code>set_dataDownlBat_fileName</code> of the user-configuration file:  <ul> <li> <code>fileBat_lcompression</code> if the file to download is compressed (.gzip) or not,</li> <li> <code>fileBat_llonFlip</code> if the longitude coordinate is defined in the rage [0:360] or [-180:+180],    </li> <li> <code>fileBat_llatInv</code> if the dataset contains latitude decreasing through the pole,    </li> <li> <code>fileBat_ldepthIncr</code> if the dataset contains seafloor elevation (positive) increases with increasing water depth,    </li> <li> <code>fileBat_lkeepSrcFull</code> if the original downloaded file needs to be deleted after cutted in the nested domain.    </li> </ul>  The available input bathymetry datasets inside the surf package is the General Bathymetric Chart of the Oceans (GEBCO), a publicly available bathymetry data sets with global coverage at 30 arc-second resolution."},{"location":"ch5_input-output-model-datasets/#coastline-dataset","title":"Coastline Dataset","text":"The coastline dataset contains borders between land and sea areas and is stored into shapefiles. The coastline is required in the child meshmask generation phase. The user needs to set-up the required parameters in the sections <code>set_dataDownlCoast</code> of the configuration file.  The available input coastline datasets inside the surf packages is the Global Self-consistent Hierarchical High-resolution Geography (GSHHG) dataset produced by the National Oceanic and Atmospheric Association (NOAA). The datasets include 20 shapefiles which provides a consistent set of hierarchically arranged closed polygons from which the shorelines are constructed. The GSHHS data are split into separate shapefiles at five different resolutions:  <ul> <li>the highest resolution is designated 'f' (full) with a resolution of xx m,</li> <li>the next highest appears as 'h' (high) with a resolution of xx m,</li> <li>the (intermediate) 'i' with a resolution of xx m,</li> <li>the (low) 'l' with a resolution of xx m,</li> <li>the (coarse) 'c' with a resolution of xx m.</li> </ul> For each level of resolution Shorelines are organized into four levels: boundary between land and ocean (L1), boundary between lake and land (L2), boundary between island-in-lake and lake (L3), and boundary between pond-in-island and island (L4). These datasets use the geographic coordinate system WGS84 (simple latitudes and longitudes; decimal degrees."},{"location":"ch5_input-output-model-datasets/#initial-condition-datasets","title":"Initial Condition Datasets","text":"In order to start a model run, the initial values for the model prognostic variables need to be specified. These include temperature, salinity, sea surface height, zonal and meridional velocity components fields. Initial condition datasets are normally provided by coarse grid model outputs. The user needs to set-up the required parameters in the sections <code>set_dataDownlOceIC</code> of the configuration file. The data can be distributed on a curvilinear spherical grid (regular or not) with unstaggered or staggered Arakawa-C grid arrangement within a region containing the nested domain. The model assumes that all the input ocean variables are defined on the same grid.   <p>The coarse-resolution ocean files contain the following variables at a certain horizontal resolution.</p> <ul> <li><p>Potential Temperature [\\(C\\)],</p></li> <li><p>Salinity [\\(PSU\\)],</p></li> <li><p>Sea surface height [\\(m\\)],</p></li> <li><p>Zonal velocity [\\(ms^{-1}\\)],</p></li> <li><p>Meridional Velocity [\\(ms^{-1}\\)].</p></li> </ul> <p>An example of CDL text representation of this file is shown in Listing 5.2.</p> <pre><code>netcdf fields_filename {\ndimensions:\n   x = 40 ;\n   y = 35 ;\n   z = 72 ;\n   time = UNLIMITED ; // (1 currently)\nvariables:\n   float lont(y, x) ;\n      lont:units = \"degrees_east\" ;\n   float latt(y, x) ;\n      latt:units = \"degrees_north\" ;\n   float deptht(z) ;\n      deptht:units = \"m\" ;\n   double time(time) ;\n      time_counter:units = \"seconds since\n                   1970-01-01 00:00:00\" ;\n   float temperature(time, z, y, x) ;\n      temperature:units = \"degC\" ;\n}\ndimensions :\nx = 677;\ny = 253;\nz = 72;\nt = UNLIMITED; // (7 currently)\nvariables : \\\\\nfloat lont(x);\n      lont: units = \"degrees_east\";\nfloat latt(y);\n      latt: units = \"degrees_north\";\nfloat deptht(z);\n      deptht: units = \"m\";\ndouble time(t);\n       time: units = \"seconds since\n                1970-01-01 00:00:00\";\nfloat temperature(t,z,y,x);\n      temperature: units = \"degC\";\n}\n</code></pre> <p>Listing 5.2: Example of a netCDF file for the Initial Condition temperature</p>   In order to perform the extrapolation (SOL) of ocean fields (see section 2.3), the parent land-sea mask file needs to be provided as input datasets. The user needs to set-up the required parameters in the sections <code>set_dataDownlOceICMesh</code> of the configuration file.   <p>This file contains all the information of the coarse-resolution ocean model grids and it includes the following variables:</p> <ul> <li><p>longitude on TUVF grid points [\\(degree\\)],</p></li> <li><p>latitude on TUVF grid points [\\(degree\\)],</p></li> <li><p>depth on TUVF grid points [\\(m\\)],</p></li> <li><p>land-sea mask on TUVF grid points [0-1],</p></li> <li><p>scalefactor on TUVF grid points [\\(m\\)],</p></li> <li><p>scalefactor on TUVF grid points [\\(m\\)],</p></li> <li><p>scalefactor on TUVF grid points [\\(m\\)].</p></li> </ul> <p>An example of CDL text representation of this file is shown in Listing 5.3.</p> <pre><code>netcdf meshmask_filename {\ndimensions :\n   x = 677;\n   y = 253;\n   z = 72;\n   t = UNLIMITED; // (7 currently)\nvariables : \\\\\n   float lon(y,x);\n   float lat(y,x);\n   float lev(z);\n   double time(t);\n   byte tmask(t,z,y,x);\n   byte umask(t,z,y,x);\n   byte vmask(t,z,y,x);\n   byte fmask(t,z,y,x);\n   float glamt(t,y,x);\n   float glamu(t,y,x);\n   float glamv(t,y,x);\n   float glamf(t,y,x);\n   float gphit(t,y,x);\n   float gphiu(t,y,x);\n   float gphiv(t,y,x);\n   float gphif(t,y,x);\n   double e1t(t,y,x);\n   double e1u(t,y,x);\n   double e1v(t,y,x);\n   double e1f(t,y,x);\n   double e2t(t,y,x);\n   double e2u(t,y,x);\n   double e2v(t,y,x);\n   double e2f(t,y,x);\n   double e3t(t,z,y,x);\n   double e3u(t,z,y,x);\n   double e3v(t,z,y,x);\n   double e3w(t,z,y,x);\n}\n</code></pre> <p>Listing 5.3: Example of a netCDF file for the Initial Condition meshmask.</p>"},{"location":"ch5_input-output-model-datasets/#lateral-open-boundary-condition-datasets","title":"Lateral Open Boundary Condition Datasets","text":"In order to integrate the primitive equations, the NEMO ocean model needs to impose appropriate boundary conditions at the ocean-ocean interface (i.e. the sides of the domain not bounded by land). Lateral Open Boundary values for the model prognostic variables need to be specified for all the simulation period. These include temperature, salinity, sea surface height, and velocity fields. The user needs to set-up the required parameters in the sections <code>set_dataDownlOceBC_preSpinup</code> and <code>set_dataDownlOceBC_postSpinup</code> of the configuration file. The data can be distributed on a curvilinear spherical grid (regular or not) with unstaggered or staggered Arakawa-C grid arrangement within a region containing the nested domain. The model assumes that all the input ocean variables in pre- and post- spinup period are defined on the same grid.   <p>The coarse-resolution ocean files contain the following variables at a certain       horizontal resolution and temporal frequency.</p> <ul> <li><p>Potential Temperature [\\(C\\)],</p></li> <li><p>Salinity [\\(PSU\\)],</p></li> <li><p>Sea surface height [\\(m\\)],</p></li> <li><p>Zonal velocity [\\(ms^{-1}\\)],</p></li> <li><p>Meridional Velocity [\\(ms^{-1}\\)].</p></li> </ul> <p>An example of CDL text representation of this file is shown in Listing 5.4.</p> <pre><code>netcdf fields_filename {\ndimensions :\n   x = 677;\n   y = 253;\n   z = 72;\n   t = UNLIMITED; // (7 currently)\nvariables : \\\\\n   float lont(x);\n         lont: units = \"degrees_east\";\n   float latt(y);\n         latt: units = \"degrees_north\";\n   float deptht(z);\n         deptht: units = \"m\";\n   double time(t);\n          time: units = \"seconds since\n                   1970-01-01 00:00:00\";\n   float temperature(t,z,y,x);\n         temperature: units = \"degC\";\n}\n</code></pre> <p> Listing 5.4: Example of a netCDF file for Open boundary Condition temperature. </p> <p>In order to perform the extrapolation (SOL) of ocean fields (see  section 2.3), the parent land-sea mask file needs to be provided as input datasets. The user needs to set-up the required parameters in the sections <code>set_dataDownlOceBCMesh</code> of the configuration file.</p> <p>This file contains all the information of the coarse-resolution ocean model grids       and it includes the following variables:</p> <ul> <li><p>longitude on TUVF grid points [\\(degree\\)],</p></li> <li><p>latitude on TUVF grid points [\\(degree\\)],</p></li> <li><p>depth on TUVF grid points [\\(m\\)],</p></li> <li><p>land-sea mask on TUVF grid points [0-1],</p></li> <li><p>scalefactor on TUVF grid points [\\(m\\)],</p></li> <li><p>scalefactor on TUVF grid points [\\(m\\)],</p></li> <li><p>scalefactor on TUVF grid points [\\(m\\)].</p></li> </ul> <p>An example of CDL text representation of this file is shown in Listing 5.5.</p> <pre><code>netcdf meshmask_filename {\ndimensions :\n   x = 677;\n   y = 253;\n   z = 72;\n   t = UNLIMITED; // (7 currently)\nvariables : \\\\\n   float lon(y,x);\n   float lat(y,x);\n   float lev(z);\n   double time(t);\n   byte tmask(t,z,y,x);\n   byte umask(t,z,y,x);\n   byte vmask(t,z,y,x);\n   byte fmask(t,z,y,x);\n   float glamt(t,y,x);\n   float glamu(t,y,x);\n   float glamv(t,y,x);\n   float glamf(t,y,x);\n   float gphit(t,y,x);\n   float gphiu(t,y,x);\n   float gphiv(t,y,x);\n   float gphif(t,y,x);\n   double e1t(t,y,x);\n   double e1u(t,y,x);\n   double e1v(t,y,x);\n   double e1f(t,y,x);\n   double e2t(t,y,x);\n   double e2u(t,y,x);\n   double e2v(t,y,x);\n   double e2f(t,y,x);\n   double e3t(t,z,y,x);\n   double e3u(t,z,y,x);\n   double e3v(t,z,y,x);\n   double e3w(t,z,y,x);\n}\n</code></pre> <p> Listing 5.5: Example of a netCDF file for the Initial Condition meshmask. </p>"},{"location":"ch5_input-output-model-datasets/#tidal-datasets-for-the-open-boundaries","title":"Tidal Datasets for the open boundaries","text":"For the barotropic solution, there is also the option to use tidal harmonic forcing at open boundaries in addition to other external data. These include the constituents for amplitude and phase of surface height and velocity. The user needs to set-up the required parameters in the sections <code>set_dataDownlTide</code> of the configuration file. The data are distributed on a regular curvilinear spherical grid with unstaggered or staggered Arakawa-C grid arrangement within a region containing the nested domain. The model assumes that all the input tidal harmonic variables are defined on the same grid.   <p>The barotropic tide files contain for each harmonic constituents the following variables at a certain       horizontal resolution.</p> <ul> <li><p>Tidal elevation complex amplitude, Real and Imaginary part [\\(mm\\)],</p></li> <li><p>Tidal WE transport complex amplitude, Real and Imaginary part [\\(cm^2/s\\)],</p></li> <li><p>Tidal SN transport complex amplitude, Real and Imaginary part [\\(cm^2/s\\)],</p></li> </ul> <p>An example of CDL text representation of this file is shown in Listing 5.6.</p> <pre><code>netcdf uv.k1_tpxo8_atlas_30c_v1 {\ndimensions:\n   nx = 10800 ;\n   ny = 5401 ;\nvariables:\n   double lon_u(nx) ;\n      lon_u:units = \"degree_east\" ;\n   double lat_u(ny) ;\n      lat_u:units = \"degree_north\" ;\n   double lon_v(nx) ;\n      lon_v:units = \"degree_east\" ;\n   double lat_v(ny) ;\n      lat_v:units = \"degree_north\" ;\n   int uRe(nx, ny) ;\n      uRe:units = \"centimeter^2/sec\" ;\n   int uIm(nx, ny) ;\n      uIm:units = \"centimeter^2/sec\" ;\n   int vRe(nx, ny) ;\n      vRe:units = \"centimeter^2/sec\" ;\n   int vIm(nx, ny) ;\n      vIm:units = \"centimeter^2/sec\" ;\n}\n</code></pre> <p> Listing 5.6: Example of a netCDF file for the Zonal and meridional Tidal transport for the constituent K1. </p> <p>The tidal model bathymetry file needs to be provided as input datasets. The user needs to set-up the required parameters in the sections <code>set_dataDownlTideMesh</code> of the configuration file.</p> <p>This file contains all the information of the tidal model grids and depth grid       and it includes the following variables:</p> <ul> <li><p>longitude on TUV grid points [\\(degree\\)],</p></li> <li><p>latitude on TUV grid points [\\(degree\\)],</p></li> <li><p>Bathymetry at TUV grid points [\\(m\\)].</p></li> </ul> <p>An example of CDL text representation of this file is shown in Listing 5.7.</p> <pre><code>netcdf grid_tpxo8atlas_30_v1 {\ndimensions:\n   nx = 10800 ;\n   ny = 5401 ;\nvariables:\n   double lon_z(nx) ;\n      lon_z:units = \"degree_east\" ;\n   double lat_z(ny) ;\n      lat_z:units = \"degree_north\" ;\n   double lon_u(nx) ;\n      lon_u:units = \"degree_east\" ;\n   double lat_u(ny) ;\n      lat_u:units = \"degree_north\" ;\n   double lon_v(nx) ;\n      lon_v:units = \"degree_east\" ;\n   double lat_v(ny) ;\n      lat_v:units = \"degree_north\" ;\n   float hz(nx, ny) ;\n      hz:units = \"meter\" ;\n   float hu(nx, ny) ;\n      hu:units = \"meter\" ;\n   float hv(nx, ny) ;\n      hv:units = \"meter\" ;\n}\n</code></pre> <p> Listing 5.7: Example of a netCDF file for the Initial Condition meshmask. </p>   The available input barotropic tide datasets inside the surf packages are derived from the Topex Poseidon cross-over (TPX08-ATLAS) global inverse tide model obtained with the software package OTIS (OSU Tidal Inversion Software) implementing methods described in Egbert and Erofeeva, 2002. The TPX08 tidal model consists of a multi-resolution bathymetric grid solution, with a 1/6 solution in the global open ocean, and a 1/30 local resolution solution to improve modelling in complex shallow-water environments. It includes complex amplitudes of the tide sea-surface elevations and transports for eight primaries (M2, S2, N2, K2, K1, O1, P1, Q1), two long-period (Mf, Mm) and 3 non-linear (M4, MS4, MN4) harmonic constituents."},{"location":"ch5_input-output-model-datasets/#atmospheric-forcing-datasets","title":"Atmospheric Forcing Datasets","text":"In order to integrate the primitive equations, the NEMO ocean model needs to impose appropriate boundary conditions on flows of mass, momentum and energy at the atmosphere-ocean interface. It must be provided on the integration domain the following six fields:  <ol> <li><p>the zonal components of the surface ocean stress,</p></li> <li><p>the meridional components of the surface ocean stress,</p></li> <li><p>the heat fluxes from solar Qsr,</p></li> <li><p>the heat fluxes from non-solar Qns radiation,</p></li> <li><p>the water flows exchanged with the atmosphere (E-P) (the evaporation minus precipitation budget).</p></li> </ol> <p>In addition an optional field:</p> <ol> <li><p>the atmospheric pressure at the ocean surface (pa).</p></li> </ol> <p>The NEMO ocean model provides different ways to provide the first six fields to the ocean which are controlled by namelist variables (see NEMO Manual). The choice of the atmospheric forcing formulation in SURF platform is obtained by setting the parameter <code>sbc_iformulat</code> in the user configuration file:</p> <ul> <li><p><code>sbc_iformulat=0</code> for the MFS bulk formulae,</p></li> <li><p><code>sbc_iformulat=1</code> for the the Flux formulation,</p></li> <li><p><code>sbc_iformulat=2</code> for the CORE bulk formula.</p></li> </ul> <p>The data are distributed on a regular unstaggered grid within a region containing the nested domain. The model assumes that input atmospheric variables in pre- and post- spinup period are defined on the same mesh but allowed different mesh for different variables. The user needs to set-up the required parameters in the sections <code>set_dataDownlAtm_preSpinup</code> and <code>set_dataDownlAtm_postSpinup</code> of the configuration file.</p> <p>(1) The choice of MFS bulk formulae is obtained by setting the parameter <code>sbc_iformulat=0</code> in the user configuration file.</p> <p>The atmospheric forcing files contain the following variables at a certain horizontal resolution and          temporal frequency:</p> <ul> <li><p>10 m zonal wind component [\\(ms^{-1}\\)],</p></li> <li><p>10 m meridional wind component [\\(ms^{-1}\\)],</p></li> <li><p>2m Air Temperature [\\(K\\)],</p></li> <li><p>2m Dew Point Temperature [\\(K\\)],</p></li> <li><p>Mean Sea Level Pressure [\\(Pa\\)],</p></li> <li><p>Total Cloud Cover [%].</p></li> <li><p>Total Precipitation [\\( m \\)].</p></li> </ul> <p>An example of CDL text representation for the atmospheric forcing file          with temporal frequency of 3 hours is shown in box in Listing 5.8.</p> <pre><code>netcdf atmFields_filename {\ndimensions :\n   lon = 245;\n   lat = 73;\n   time = UNLIMITED; // (8 currently)\nvariables : \\\\\n   float lon(lon);\n         lon: units = \"degrees_east\";\n   float lat(lat);\n         lat: units = \"degrees_north\";\n   float time(time);\n         time: units = \"seconds since\n                  1970-01-01 00:00:00\";\n   float T2M(time,lat,lon);\n         T2M: units = \"K\";\n}\n</code></pre> <p> Listing 5.8: Example of a netCDF file for the Atmospheric Forcing temperature. </p> <p>(2) The choice of Core bulk formulae is obtained by setting the parameter <code>sbc_iformulat=2</code> in the user configuration file.</p> <p>The atmospheric forcing files contain the following variables at a certain horizontal resolution          and temporal frequency:</p> <ul> <li><p>10 m zonal wind component [\\(ms^{-1}\\)],</p></li> <li><p>10 m meridional wind component [\\(ms^{-1}\\)],</p></li> <li><p>2m Temperature [\\(K\\)],</p></li> <li><p>2m Specific humidity [\\(\\%\\)],</p></li> <li><p>Incoming long-wave radiation [\\(W m^{-2}\\)],</p></li> <li><p>Incoming short-wave radiation [\\(W m^{-2}\\)],</p></li> <li><p>Total precipitation (liquid+solid) [\\(Kg m^{-2} s^{-1}\\)],</p></li> <li><p>Solid precipitation [\\(Kg m^{-2} s^{-1}\\)].</p></li> </ul> <p>An example of CDL text representation for the atmospheric forcing file          with temporal frequency of 3 hours is shown in box in Listing 5.9.</p> <pre><code>netcdf atmFields_filename {\ndimensions :\n   lon = 245;\n   lat = 73;\n   time = UNLIMITED; // (8 currently)\nvariables : \\\\\n   float lon(lon);\n         lon: units = \"degrees_east\";\n   float lat(lat);\n         lat: units = \"degrees_north\";\n   float time(time);\n         time: units = \"seconds since\n                  1970-01-01 00:00:00\";\n   float T2M(time,lat,lon);\n         T2M: units = \"K\";\n}\n</code></pre> <p> Listing 5.9: Example of a netCDF file for the Atmospheric Forcing temperature. </p> <p>(3) The choice of Flux formulation is obtained by setting the parameter <code>sbc_iformulat=1</code> in the user configuration file.</p> <p>The atmospheric forcing files contain the following          variables at a certain horizontal resolution and          temporal frequency:</p> <ul> <li><p>Zonal wind stress [0 - 1],</p></li> <li><p>Meridional Wind stress [0 - 1],</p></li> <li><p>Total heat flux [0 - 1],</p></li> <li><p>Solar Radiation Penetration [0 - 1],</p></li> <li><p>Mass flux exchanged [0 - 1],</p></li> <li><p>Surface Temperature [0 - 1],</p></li> <li><p>Surface Salinity [0 - 1].</p></li> </ul> <p>An example of CDL text representation for the atmospheric forcing file          with temporal frequency of 3 hours is shown in box in Listing 5.10.</p> <pre><code>netcdf atmFields_filename {\ndimensions :\n   lon = 245;\n   lat = 73;\n   time = UNLIMITED; // (8 currently)\nvariables : \\\\\n   float lon(lon);\n         lon: units = \"degrees_east\";\n   float lat(lat);\n         lat: units = \"degrees_north\";\n   float time(time);\n         time: units = \"seconds since\n                  1970-01-01 00:00:00\";\n   float T2M(time,lat,lon);\n         T2M: units = \"K\";\n}\n</code></pre> <p> Listing 5.10: Example of a netCDF file for the Atmospheric Forcing temperature. </p> <p>In order to perform the extrapolation (SOL) of atmospheric fields (see  section 2.3), the atmospheric meshmask file needs to be provided as input datasets. The user needs to set-up the required parameters in the sections <code>set_dataDownlAtmMesh</code> of the configuration file.</p> <p>The atmospheric meshmask file contains the land-sea mask [0-1] variable.</p> <p>An example of CDL text representation of the atmospheric land-sea mask is shown in Listing 5.11.       The time dimension and coordinate variable can also be omitted.</p> <pre><code>netcdf meshmask_filename {\ndimensions :\n   lon = 245;\n   lat = 73;\n   time = UNLIMITED; // (1 currently)\nvariables : \\\\\n   float lon(lon);\n         lon: units = \"degrees_east\";\n   float lat(lat);\n         lat: units = \"degrees_north\";\n   float time(time);\n         time: units = \"seconds since\n                  1970-01-01 00:00:00\";\n   float LSM(time,lat,lon);\n         LSM: units = \"0-1\";\n}\n</code></pre> <p> Listing 5.11: Example of a netCDF file for the Atmospheric Forcing meshmask. </p>"},{"location":"ch5_input-output-model-datasets/#output-datasets","title":"Output Datasets","text":"<p>The output model datasets are provided in the NetCDF format .. the meshmask file, the output files for T, U ,V, W grids and the restart file.</p>"},{"location":"ch5_input-output-model-datasets/#meshmask-dataset","title":"Meshmask dataset","text":"This file contains all the information of the child ocean model grids       and it includes the following variables:       <ul> <li>longitude on TUVF grid points [\\(degree\\)],</li> <li>latitude on TUVF grid points [\\(degree\\)],</li> <li>depth on TUVF grid points [\\(m\\)],</li> <li>land-sea mask on TUVF grid points [0-1],</li> <li>scalefactor on TUVF grid points [\\(m\\)],</li> <li>scalefactor on TUVF grid points [\\(m\\)],</li> <li>scalefactor on TUVF grid points [\\(m\\)].</li> </ul>       An example of CDL text representation of this file is shown in Listing 5.21.     <pre><code>netcdf meshmask_filename {\ndimensions :\n   x = 677;\n   y = 253;\n   z = 72;\n   t = UNLIMITED; // (7 currently)\nvariables : \\\\\n   float lon(y,x);\n   float lat(y,x);\n   float lev(z);\n   double time(t);\n   byte tmask(t,z,y,x);\n   byte umask(t,z,y,x);\n   byte vmask(t,z,y,x);\n   byte fmask(t,z,y,x);\n   float glamt(t,y,x);\n   float glamu(t,y,x);\n   float glamv(t,y,x);\n   float glamf(t,y,x);\n   float gphit(t,y,x);\n   float gphiu(t,y,x);\n   float gphiv(t,y,x);\n   float gphif(t,y,x);\n   double e1t(t,y,x);\n   double e1u(t,y,x);\n   double e1v(t,y,x);\n   double e1f(t,y,x);\n   double e2t(t,y,x);\n   double e2u(t,y,x);\n   double e2v(t,y,x);\n   double e2f(t,y,x);\n   double e3t(t,z,y,x);\n   double e3u(t,z,y,x);\n   double e3v(t,z,y,x);\n   double e3w(t,z,y,x);\n}\n</code></pre> <p>Listing 5.21: CDL example for the meshmask datasets.</p>"},{"location":"ch5_input-output-model-datasets/#ocean-output-datasets","title":"Ocean Output Datasets","text":"<p>\u2026contains:</p> <p>(1) This output file SURF_1h_YYYYMMDD0_YYYYMMDD1_grid_T contains hourly fields defined on the Arakawa-T grid within the chid nested domain.</p> <p> This file contains the following variables:</p> <ul> <li>Temperature [\\(C\\)],</li> <li>Salinity [\\(PSU\\)],</li> <li>Sea Surface temperature [\\(C\\)],</li> <li>Sea Surface salinity [\\(PSU\\)],</li> <li>Sea Surface Height [\\(m\\)],</li> <li>Net Upward Water Flux [\\(Kg=m2=s\\)],</li> <li>concentration/dilution water flux [\\(Kg=m2=s\\)],</li> <li>Surface Salt Flux [\\(Kg=m2=s\\)],</li> <li>Net Downward Heat Flux [\\(W=m2\\)],</li> <li>Shortwave Radiation [\\(W=m2\\)],</li> <li>Turbocline Depth [\\(m\\)],</li> <li>Mixed Layer Depth 0.01 [\\(W=m2\\)],</li> <li>Ice fraction [\\(0;1\\)],</li> <li>wind speed at 10m [\\(m=s\\)],</li> <li>Surface Heat Flux: Damping [\\(W=m2\\)],</li> <li>Surface Water Flux: Damping [\\(Kg=m2=s\\)],</li> <li>Surface salt flux: damping [\\(Kg=m2=s\\)],</li> <li>Bowl Index[\\(W point\\)].</li> </ul> <p>An example of CDL text representation of this file is shown in Listing 5.22.</p> <pre><code>netcdf fields_filename {\ndimensions :\n   lon = 677;\n   lat = 253;\n   depth = 72;\n   time = UNLIMITED; // (7 currently )\nvariables : \\\\\n   float lont (x);\n         lont : units = \" degrees_east \";\n   float latt (y);\n         latt : units = \" degrees_north \";\n   float deptht (z);\n         deptht : units = \"m\";\n   double time (t);\n         time : units = \" seconds since\n                   1970-01-01 00:00:00\";\n   float temperature (t, z, y, x);\n         temperature : units = \" degC \";\n}\n</code></pre> <p>Listing 5.22: CDL example for the bdyV_u3d data.</p> <p>(2) This output file SURF_1h_YYYYMMDD0_YYYYMMDD1_grid_U contains hourly fields defined on the Arakawa-U grid within the chid nested domain.</p> <p> This file contains the following variables: </p> <ul> <li><p>Zonal Current [\\(m/s\\)],</p></li> <li><p>Wind Stress along zonal-axis [\\(N/m^2\\)],</p></li> </ul> <p>An example of CDL text representation of this file is shown in Listing 5.23.</p> <pre><code>netcdf fields_filename {\ndimensions :\n   lon = 677;\n   lat = 253;\n   depth = 72;\n   time = UNLIMITED; // (7 currently )\nvariables : \\\\\n   float lont (x);\n         lont : units = \" degrees_east \";\n   float latt (y);\n         latt : units = \" degrees_north \";\n   float deptht (z);\n         deptht : units = \"m\";\n   double time (t);\n         time : units = \" seconds since\n                   1970-01-01 00:00:00\";\n   float temperature (t, z, y, x);\n         temperature : units = \" degC \";\n}\n</code></pre> <p>Listing 5.23: CDL example for the bdyV_u3d data.</p> <p>(3) This output file SURF_1h_YYYYMMDD0_YYYYMMDD1_grid_V contains hourly fields defined on the Arakawa-V grid within the chid nested domain.</p> <p> This file contains the following variables: </p> <ul> <li><p>Meridional Current [\\(m/s\\)],</p></li> <li><p>Wind Stress along meridional-axis [\\(N/m^2\\)],</p></li> </ul> <p>An example of CDL text representation of this file is shown in Listing 5.23.</p> <pre><code>netcdf fields_filename {\ndimensions :\n   lon = 677;\n   lat = 253;\n   depth = 72;\n   time = UNLIMITED; // (7 currently)\nvariables : \\\\\n   float lont(x);\n         lont: units = \"degrees_east\";\n   float latt(y);\n         latt: units = \"degrees_north\";\n   float deptht(z);\n         deptht: units = \"m\";\n   double time(t);\n         time: units = \"seconds since\n                  1970-01-01 00:00:00\";\n   float temperature(t,z,y,x);\n         temperature: units = \"degC\";\n}\n</code></pre> Listing 5.24: CDL example for the bdyV_u3d data. <p>(4) This output file SURF_1h_YYYYMMDD0_YYYYMMDD1_grid_W contains hourly fields defined on the Arakawa-W grid within the chid nested domain.</p> <p> This file contains the following variables: </p> <ul> <li><p>Vertical velocity [\\(m/s\\)],</p></li> <li><p>Vertical Eddy Viscosity [\\(m^2/s\\)],</p></li> <li><p>Vertical Eddy Diffusivity [\\(m^2/s\\)].</p></li> </ul> <p>An example of CDL text representation of this file is shown in Listing 5.23.</p> <pre><code>netcdf fields_filename {\ndimensions :\n   lon = 677;\n   lat = 253;\n   depth = 72;\n   time = UNLIMITED; // (7 currently)\nvariables : \\\\\n   float lont(x);\n         lont: units = \"degrees_east\";\n   float latt(y);\n         latt: units = \"degrees_north\";\n   float deptht(z);\n         deptht: units = \"m\";\n   double time(t);\n         time: units = \"seconds since\n                  1970-01-01 00:00:00\";\n   float temperature(t,z,y,x);\n         temperature: units = \"degC\";\n}\n</code></pre> Listing 5.24: CDL example for the bdyV_u3d data."},{"location":"ch5_input-output-model-datasets/#restart-dataset","title":"Restart dataset","text":"<p>The restart file can be used as initial conditions for research ...</p> <p>This file contains all the information of the child ocean model grids       and it includes the following variables:</p> <ul> <li><p>longitude on TUVF grid points [\\(degree\\)],</p></li> <li><p>latitude on TUVF grid points [\\(degree\\)],</p></li> <li><p>depth on TUVF grid points [\\(m\\)],</p></li> </ul> <p>An example of CDL text representation of this file is shown in Listing 5.21.</p> <pre><code>netcdf SURF_restart_20141005 {\ndimensions:\nx = 94 ;\ny = 79 ;\nz = 120 ;\nt = UNLIMITED ; // (1 currently)\nvariables:\nfloat nav_lon(y, x) ;\nfloat nav_lat(y, x) ;\nfloat nav_lev(z) ;\ndouble time_counter(t) ;\ndouble kt ;\ndouble ndastp ;\ndouble adatrj ;\ndouble utau_b(t, y, x) ;\ndouble vtau_b(t, y, x) ;\ndouble qns_b(t, y, x) ;\ndouble emp_b(t, y, x) ;\ndouble sfx_b(t, y, x) ;\ndouble sbc_hc_b(t, y, x) ;\ndouble sbc_sc_b(t, y, x) ;\ndouble qsr_hc_b(t, z, y, x) ;\ndouble fraqsr_1lev(t, y, x) ;\ndouble rdt ;\ndouble rdttra1 ;\ndouble ub(t, z, y, x) ;\ndouble vb(t, z, y, x) ;\ndouble tb(t, z, y, x) ;\ndouble sb(t, z, y, x) ;\ndouble rotb(t, z, y, x) ;\ndouble hdivb(t, z, y, x) ;\ndouble sshb(t, y, x) ;\ndouble un(t, z, y, x) ;\ndouble vn(t, z, y, x) ;\ndouble tn(t, z, y, x) ;\ndouble sn(t, z, y, x) ;\ndouble rotn(t, z, y, x) ;\ndouble hdivn(t, z, y, x) ;\ndouble sshn(t, y, x) ;\ndouble rhop(t, z, y, x) ;\n}\n</code></pre> <p>Listing 5.21: CDL example for the restart datasets.</p>"},{"location":"ch6_quick-start-guide/","title":"Getting Started with SURF-NEMO","text":"This chapter describes how you can quickly get started with the SURF platform. We show how to download and install the SURF Virtual Machine and all the SURF packages. We describe how to compile (if needed) the source codes. We present how to execute a case study (template) experiment in the Gulf of Taranto and view the results. Finally we show how the user-configuration file of a template experiment can be modified in order to execute and analysis new experiments. The template experiment makes it easier to run the model without detailed knowledge of the underlying scientific basis. Only a limited number of default values need to be changed for most applications. A more specific scientific background is required if for example, the user intends to perform experiments with different turbulence or numerical schemes or with alternative settings of model parameters. It is then recommended to read first the NEMO Model Description document and relative article. See also the video tutorials available online here explain the basic features of the SURF platform and designed for beginners who want to learn SURF step by step."},{"location":"ch6_quick-start-guide/#download-and-install-surf-virtual-machine","title":"Download and Install SURF Virtual Machine","text":"The SURF platform will be provided as a Virtual Machine (VM). It is packaged and distributed as a ZIP Compressed Archive file (with a .zip extension). The general scheme adopted to manage the versions provides that the releases contain in the name indications of the version in the format:  <pre><code>surf_vm_VERSION.zip\n</code></pre>  where VERSION is a number (e.g. surf_vm_1.01.zip for the current version). The instructions below explain how to download, install and configure the SURF VM in Oracle VirtualBox   <ul> <li>Navigate to https://www.virtualbox.org/ and click on Downloads button.         Choose the <code>VirtualBox base package</code> (version &gt;=6) corresponding to the host         operating system of your computer (i.e. Windows, Mac, Linux).         Save the corresponding file on your computer, double-click it to open it, and follow the installation instructions.         </li> </ul> Downloads VirtualBox base package. <ul> <li>In addition to the base package, download also the <code>Extension Packs</code>.           This package provides additional functionality to the base package, such as virtual USB device, remote desktop support, ecc.           To install this extension, simply double-click on the package file and follow the installation instructions.           Please install the same version extension pack as your installed version of the VirtualBox base package.       </li> </ul> Downloads VirtualBox Extension Packs. <ul> <li>           Download the current version (v1.01) of the SURF virtual machine from           SURF web-page.           In the virtual machines is installed the Debian GNU/Linux 8.11 operating system.           The Guest Additions have been also installed to optimize the guest operating system for better performance and usability.           Extract than the package in your VirtualBox directory which Oracle VM VirtualBox creates in the current system user's home directory           (i.e. <code>/Users/USERNAME/VirtualBox VMs/</code> for Mac user).           ```bash           unzip surf_1.01.zip           ```         </li> </ul> Downloads SURF Virtual Machine. <ul> <li>Open the VirtualBox software. From the menu, choose Machine &gt; add and navigate to the file <code>surf.vbox</code>.         This file is an XML file that contains settings of the Machine.         This will add the Virtual Machine <code>surf</code> to the list of Virtual Machine</li> </ul> Add SURF-VM in VirtualBox. <ul> <li>To start the VM surf, you can double-click on its entry in the list in the VirtualBox Manager window or select its entry and press the Start button at the top of the window. A window opens.         The VM Login should look like the          figure 6.5 .         In the login dialogue box enter:         <ul> <li>surf as login</li> <li>surf2019 as an initial password</li> </ul>         You are now logged into the VM.       </li> </ul> Start SURF-VM."},{"location":"ch6_quick-start-guide/#disk-partitions-mounted-on-the-surf-virtual-machine","title":"Disk Partitions mounted on the SURF Virtual Machine","text":"The SURF Virtual Machine package contains two VDI (VirtualBox Disk Image) files: <ul> <li><code>surf.vdi</code> containing the Debian GNU/Linux operating system (version 10.3)</li> <li><code>surf_scratch.vdi</code> thought to contain source code files, datasets sample and experiments.</li> </ul> From the guest operating system you can see the list of partitions by typing the following command:  <pre><code>sudo fdisk -l\n</code></pre>  It is divided into two main partitions: <ul> <li>the disk <code>/dev/sda</code> \"mounted\" as filesystems to the root directory <code>/</code></li> <li>the disk <code>/dev/sdb</code> \"mounted\" in the directory <code>/scratch</code>.</li> </ul> Optionally you can mount other physical hard disks with VirtualBox (see the VirtualBox Manual for details). VirtualBox has the ability to  mount a shared folder between host and guest in order to access files of your host system from within the guest system. There are a few steps involved:  <ul> <li>Shut down the virtual OS before you can edit settings.</li> <li>Select the surf VM in the VirtualBox Manager and click Settings.</li> <li>Select Shared Folders, and click the Plus button to add a new shared folder. Specify the host folder you want to share.</li> <li>Select auto-mount and then click OK.</li> <li>You can now re-start the VM surf. The shared folder is mounted into the /media directory, along with the prefix \"sf_\".</li> </ul> Mount shared folders."},{"location":"ch6_quick-start-guide/#changing-configuration-on-the-surf-virtual-machine","title":"Changing Configuration on the SURF Virtual Machine","text":"By default, the VM surf is configurated as in table  Table 6.1 . You can keep all defaults parameters or if it is not adequate for your application you can change settings. To change the configuration you need to shut down the virtual OS before you can edit settings.   <ul> <li>Select the surf VM in the VirtualBox Manager, right-click it and choose Setting.</li> <li>increase/decrease the number of cores based on your performance desires.</li> <li>increase/decrease the number of GB of RAM allocated to your VM according to the size of your computational domain.</li> <li>increase/decrease the video memory and scale factor of your screen</li> </ul> Change VM configurations.   If you want to add more storage space to a VM you can also expande the virtual hard disk. There are a few steps involved:   <ul> <li> With the VM Power off, open a terminal and move to the location of the surf_scratch.vdi file that you want to resize,         </li> <li> At the terminal prompt, type the command:         ```bash         VBoxManage modifyhd surf_scratch.vdi          --resize SIZE_MB         ```         </li> </ul> Enlarge the virtual disk. <ul> <li> Restart the SURF VM and open the GParted application from the Application Menu </li> <li> Select the /dev/sdb partition (an unlocated drive space is now available). Resize to the unalocated area</li> </ul> Enlarge the virtual disk.  Table 6.1 Virtual Machine Summary Fields.  Parameter Description Values Name Name given the VM surf Guest OS Operating system running on this VM Debian Linux Memory Amount of memory available to this VM 2 [GB] Cores Number of CPU cores being used by this VM 2 Disk Capacity Total disk capacity available to this VM 40 [GB] Network Adapters Number of network adapters available to this VM 1 IP Address IP address assigned to the VM x"},{"location":"ch6_quick-start-guide/#download-and-install-surf-packages","title":"Download and Install SURF packages","text":"Once logged in, open a new terminal window and go to the directory <code>/scratch</code>. The scratch directory follows the directory structure as shown in Fig. B.1. The VM you have installed does not contain the SURF packages (source codes and static datasets) and you need to download and install them. The SURF packages are packaged and distributed as a GZIP Compressed Tar Archive file (with a .tar.gz extension). The general scheme adopted to manage the versions provides that the releases contain in the name indications of the version in the format:  <pre><code>packageName_&lt;VERSION&gt;.tar.gz\n</code></pre>  where &lt;VERSION&gt; is a number (e.g. surf_nemo_1.01.tar.gz for the current version of the surf_nemo package). The instructions below explain how to install the package in the VM: <ul> <li>       Once logged in the VM surf, download the current version of the SURF-NEMO (surf_nemo_1.01.tar.gz)       and SURF-DATASETS (surf_datasets_1.01.tar.gz) packages directly from the       SURF web-page       and save it in the directory <code>/scratch/surf/surf_install/releases/</code>       (for simplicity, we abbreviate this location as <code>$SURF_RELEASES</code>).     </li> <li>       Go to the directory <code>$SURF_RELEASES</code> and run the installation bash script       <code>install.sh</code> followed by the package name. For the SURF-NEMO packages type:       ```bash       cd $SURF_RELEASES ; install.sh surf_nemo_1.01.tar.gz       ```       For the SURF-DATASETS packages type:       ```bash       cd $SURF_RELEASES ; install.sh surf_datasets_1.01.tar.gz       ```       The installation process will extract the archive in the directory <code>/scratch/surf/surf_nemo/</code> and       <code>/scratch/surf/surf_datasets/</code>, respectively, and will create a symbolic link <code>current</code> in this directory       that points to the extracted folder (for simplicity, we abbreviate this location as <code>$SURF_NEMO</code>, <code>$SURF_DATASETS</code>, respectively).     </li> </ul> For a detailed description of the directory structure and contents of each package refer to the Appendix B."},{"location":"ch6_quick-start-guide/#compiling-the-source-code","title":"Compiling the source code","text":"After the installation of the SURF-NEMO package is finished, you need to compile the source codes in order to create the executable files needed to perform specific tasks. The executable files should not be recreated unless you need to modify the source code. The compilation is performed with the Unix/Linux make utility using the following tools: (1) fortran 90 compiler, (2) C-preprocessor cpp, (3) a compiled MPI library for simulations in parallel mode. (4) a compiled netCDF library to read and write data in portable netCDF format. All these tools are already present and compiled in the SURF platform. To compile the source codes go to the directory <code>/scratch/surf/surf_nemo/current/scripts/</code> and run the compilation bash script <code>compile.sh</code> followed by the package name (or by the word 'all' to compile all the packages):   <pre><code>cd /scratch/surf/surf_nemo/current/scripts; ./compile_codes.sh all\n</code></pre>   Compilation could take a few minutes and it will create the executable files for each program present in the SURF-NEMO package."},{"location":"ch6_quick-start-guide/#running-the-case-study-gulf-of-taranto","title":"Running the case study: Gulf of Taranto","text":"As case study we implement the SURF platform in the Gulf of Taranto in the northern Ionian Sea (fig xx). The nesting simulation starts on 5 October 2014 at 00:00 and run until 7 October 2014 at 24:00. In order to execute this case study experiment, you can follow these steps:  <ul> <li>       Download the input datasets (gulfTaranto_20141005.tar.gz) of this case study directly from the web-repository       (https://www.surf-platform.org)       and extract it in the directory <code>/scratch/surf/indata_offline/</code>       ```bash       tar -zxvf gulfTaranto_20141005.tar.gz       ```       Note If you want to change the local repository path to some other location of your choice make sure to change the path in the configuration file.     </li> <li>       Create a new folder in the directory <code>/scratch/from_GUI/</code> and let's call it gulfTaranto_20141005.       This is the Experiment ID name which uniquely identifies the experiment.       ```bash       cd /scratch/from_GUI/; mkdir gulfTaranto_20141005       ```     </li> <li>       Copy the template configuration file <code>/scratch/surf/surf_nemo/current/setParFree.json</code> in the       directory <code>/scratch/from_GUI/gulfTaranto_20141005/</code> which contains the configuration for this case study.       ```bash       necd; cp setParFree.json /scratch/from_GUI/gulfTaranto_20141005/       ```     </li> <li>       After that, from the directory <code>/scratch/surf/surf_nemo/current/scripts/</code>, you just need to execute       the Julia script <code>run_exp.jl</code> followed by the experiment ID <code>gulfTaranto_20141005</code>       ```bash       julia run_exp.jl gulfTaranto_20141005       ```       This will create the folder gulfTaranto_20141005 in the directory <code>/scratch/surf/experiments/</code>       with a directory tree as in fig.x.1 (refer to the Appendix B for more details)     </li> </ul> You can activate/deactivate specific tasks by setting logical parameters to True/False in the section <code>set_lrun</code> of the configuration file <code>setParFree.json</code> <code>lrun_childMeshmask</code> to  enable the execution of the CHILD-MESHMASK GENERATION task.  <code>lrun_regridPreAtm</code> to enable the execution of the ATMOSPHERIC-DATA-REGRIDDING task.  <code>lrun_regridPreOceIC</code> to enable the execution of the OCEAN-IC-DATA-REGRIDDING task.  <code>lrun_regridPreOceBC</code> to enable the execution of the OCEAN-BC-DATA-REGRIDDING task.  <code>lrun_regridPreWeights</code> if you want to compute (=True) or just copy (=False) the WEIGHT-FILEs for REMAPPING in the Regridding phase.  <code>lrun_ocean</code> to enable the execution of the NEMO code.     <pre><code>{\n\"id\":\"A001\",\"title\":\"set_lrun\",\n\"items\": [\n      {\"name\": \"lrun_childMeshMask\",\n      \"value\": \"True\"\n      },\n      {\"name\": \"lrun_regridPreAtm\",\n      \"value\": \"True\"\n      },\n      {\"name\": \"lrun_regridPreOceIC\",\n      \"value\": \"True\"\n      },\n      {\"name\": \"lrun_regridPreOceBC\",\n      \"value\": \"True\"\n      },\n      {\"name\": \"lrun_regridPreWeights\",\n      \"value \": \"True\"\n      },\n      {\"name\": \"lrun_ocean\",\n      \"value\": \"True\"\n      }\n   ]\n}\n</code></pre>"},{"location":"ch6_quick-start-guide/#post-processing-the-results","title":"Post-processing the results","text":"The surf package is provided together with open source tools for data visualization and post-processing your data. You will find the free software packages NcView with a graphical user interface and a suite of procedure using NCAR Graphics package with NCL and Python interface you can call from Command Line. However, it is very well possible to use other (free or commercial) graphic software such as Pynoply or several scripting languages such as Julia, IDL, Matlab, as long as they can read the netCDF format."},{"location":"ch6_quick-start-guide/#visualizing-the-results-with-ncview","title":"Visualizing the results with Ncview","text":"Ncview is a tool for visualizing netCDF data files. It is very easy to use, because of its graphical user interface. However, its possibilities are limited. Typically you would use ncview to get a quick and easy, push-button look at your netCDF files. You can view simple movies of the data, view along various dimensions, take a look at the actual data values, change colour maps, invert the data, etc. In order to start this program type ncview followed by the filename of the dataset you want to visualize, example type the following command:   <pre><code>ncview SURF_1h_20141006_20141006_grid_T.nc\n</code></pre>   An example of the user interface in NcView is given in figure Fig. 6.7 Screenshot of using NcView."},{"location":"ch6_quick-start-guide/#analyzing-and-visualizing-results-using-ncar-graphic-packages","title":"Analyzing and Visualizing results using NCAR graphic packages","text":"NCAR Graphics is a collection of graphics libraries that support the display of scientific data. One possible interface available for visualizing data with these libraries is with the NCAR Command Language (NCL), an open-source interpreted programming language, developed at NCAR and designed for the analysis and visualization of geoscientific data. The SURF-NEMO package include, as postprocessing, a suite of NCL functions to visualize the input/output datasets, compare the child/parent fields, compare the simulation result with in-situ or satellite datasets and convert datasets.   (A) Surface current. (B) Surface temperature. (C) Cross-section of temperature. Example figure generated using NCAR graphic packages.   In order to Post-processing the results of an existing experiment, you need to execute the Julia script <code>run_postProc.jl</code> followed by the experiment ID. Example for the case study experiment type the following command:   <pre><code>julia run_postproc.jl gulfTaranto_20141005\n</code></pre>   You can activate/deactivate specific tasks by setting logical parameters to True/False in the sections <code>set_lrun_post</code> and <code>set_visual_lplot</code> of the configuration file <code>setParFree.json</code> <code>lrun_visDom</code> to  enable the plotting of the user-defined domains. <code>lrun_visIndata</code> to  enable the plotting of the Indata Bat, Atm, OceIC, OceBC fields. <code>lrun_visExtrapdata</code> to enable the plotting of the Extrapdata Atm, OceIC, OceBC fields. <code>lrun_visRegriddata</code> to enable the execution of the OCEAN-IC-DATA-REGRIDDING task. <code>lrun_visOutdata</code> to enable the execution of the OCEAN-BC-DATA-REGRIDDING task. <code>lrun_chlVSpar</code> if you want to compute (=True) or just copy (=False) the WEIGHT-FILEs for REMAPPING in the Regridding phase. <code>lrun_surfVSctd</code> enables the execution of the NEMO code. <code>lrun_surfVSsat</code> enables the execution of the NEMO code. <code>lrun_surfVSmooring</code> enables the execution of the NEMO code. <code>lrun_surfVSferrybox</code> enables the execution of the NEMO code. <pre><code>{\n  \"id\":\"B000\",\"title\":\"set_lrun_post\",\n  \"items\": [\n     {\"name\": \"lrun_visDom\",\n     \"value\": \"True\"\n     },\n     {\"name\": \"lrun_visIndata\",\n     \"value\": \"True\"\n     },\n     {\"name\": \"lrun_visExtrapdata\",\n     \"value\": \"True\"\n     },\n     {\"name\": \"lrun_visRegriddata\",\n     \"value\": \"True\"\n     },\n     {\"name\": \"lrun_visOutdata\",\n     \"value \": \"True\"\n     },\n     {\"name\": \"lrun_chlVSpar\",\n     \"value\": \"True\"\n     },\n     {\"name\": \"lrun_surfVSctd\",\n     \"value\": \"True\"\n     },\n     {\"name\": \"lrun_surfVSsat\",\n     \"value\": \"True\"\n     },\n     {\"name\": \"lrun_surfVSmooring\",\n     \"value\": \"True\"\n     },\n     {\"name\": \"lrun_surfVSferrybox\",\n     \"value\": \"True\"\n     }\n  ]\n}\n</code></pre> <code>lplotMesh</code> to  enable plotting of the Child MeshMask fields. <code>lplotBat</code> to enable the plotting of the Bathymetry fields. <code>lplotAtm</code> to enable the plotting of the Atmospheric fields. <code>lplotOceIC</code> to enable the plotting of the Initial Condition Ocean fields. <code>lplotOceBC</code> to enable the plotting of the Open Boundary Condition Ocean fields. <code>lplotOceBCbdy</code> to enable the plotting of the Open Boundary Condition Ocean fields. <code>lplotOceOut</code> to enable the plotting of the Output Ocean fields. <pre><code>{\n   \"id\":\"B001\",\"title\":\"set_visual_lplot\",\n      \"items\": [\n      {\"name\": \"lplotMesh\",\n      \"value\": \"True\"\n      },\n      {\"name\": \"lplotBat\",\n      \"value\": \"True\"\n      },\n      {\"name\": \"lplotAtm\",\n      \"value\": \"True\"\n      },\n      {\"name\": \"lplotOceIC\",\n      \"value\": \"True\"\n      },\n      {\"name\": \"lplotOceBC\",\n      \"value\": \"True\"\n      },\n      {\"name\": \"lplotOceBCbdy\",\n      \"value\": \"True\"\n      },\n      {\"name\": \"lplotOceOut\",\n      \"value\": \"True\"\n      }\n   ]\n}\n</code></pre>"},{"location":"ch6_quick-start-guide/#make-a-new-experiments","title":"Make a new experiments","text":"<p>Let's assume you want to study the circulation of the Sermilik fjord in Greenland from 1 February 2017 at 00:00 to 7 February 2017 at 24:00 ... add more details.</p> <ul> <li>       Choose the name of experiment ID (e.g. <code>greenlandFjord_20170201</code>) and create the folder       ```bash       cd /scratch/from_GUI/; mkdir greenlandFjord_20170201       ```   </li> <li>       Copy the template configuration file <code>/scratch/surf/surf_nemo/current/setParFree.json</code> in the       directory <code>/scratch/from_GUI/greenlandFjord_20170201</code>       ```bash       cp /scratch/surf/surf_nemo/current/setParFree.json ./greenlandFjord_20170201/       ```   </li> <li>       Modify the user configuration file <code>setParFree.json</code> according to your needs       <code>         param1 = xxx          param2 = xxx          param3 = xxx          param4 = xxx       </code> </li> <li>       From the directory <code>/scratch/surf/surf_nemo/current/scripts/</code>, execute       the Julia script <code>run_exp.jl</code> followed by the experiment ID <code>greenlandFjord_20170201</code>       ```bash       cd /scratch/surf/surf_nemo/current/scripts/;       julia run_exp.jl greenlandFjord_20170201       ```   </li> <li>       After running the simulation, you can display the simulation results by using       the Julia script <code>run_postproc.jl</code> followed by the experiment ID <code>greenlandFjord_20170201</code>       ```bash       cd /scratch/surf/surf_nemo/current/scripts/;       julia run_postproc.jl greenlandFjord_20170201       ```   </li> </ul> <p>In principle you can simply use the template model and modify it to your needs, and not be too much concerned with the input files they create. But our advice is never to use the template model as black boxes. It is therefore important to understand how the codes work, which options they have and how their input files are structured.</p>"},{"location":"ch6_quick-start-guide/#multiple-downscaling-experiments","title":"Multiple downscaling experiments","text":"<p>SURF-NEMO package includes multiple nesting capability (i.e. consecutive nested models can be implemented with increasing grid resolutions). Let's assume you want to downscale from an existing experiment (e.g. from the template experiment <code>gulfTaranto_20141005</code>) in order to increase the spatial resolution to 800m ... add details.</p> <ul> <li>       Go to the existing experiment directory       ```bash       cd /scratch/surf/experiments/gulfTaranto_20141005/       ```   </li> <li>       Modify the user configuration file <code>setParFree.json</code> according to your needs       <code>         param1 = xxx          param2 = xxx          param3 = xxx          param4 = xxx       </code> </li> <li>       From the directory <code>/scratch/surf/experiments/gulfTaranto_20141005/code/ocean/scripts/</code>,       execute the Julia script <code>run_exp.jl</code> followed by the experiment ID <code>gulfTaranto_20141005</code>       ```bash       cd /scratch/surf/experiments/gulfTaranto_20141005/code/ocean/scripts/;       julia run_exp.jl gulfTaranto_20141005       ```   </li> <li>       After running the simulation, you can display the simulation results by using the julia script       <code>run_postproc.jl</code> followed by the experiment ID <code>gulfTaranto_20141005</code>       ```bash       julia run_postproc.jl gulfTaranto_20141005       ```   </li> </ul>"}]}